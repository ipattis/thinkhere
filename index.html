<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>ThinkHere — In-Browser AI</title>
<link rel="icon" type="image/svg+xml" href="favicon.svg">
<link rel="preconnect" href="https://fonts.googleapis.com">
<link href="https://fonts.googleapis.com/css2?family=DM+Mono:wght@300;400;500&family=Instrument+Serif:ital@0;1&family=DM+Sans:wght@300;400;500;600&display=swap" rel="stylesheet">
<style>
  :root {
    --bg: #0c0c0e;
    --surface: #141418;
    --surface-2: #1c1c22;
    --border: #2a2a34;
    --text: #e8e6e1;
    --text-dim: #8a8890;
    --text-faint: #55535c;
    --accent: #c4f06e;
    --accent-dim: #8aaa4e;
    --accent-glow: rgba(196, 240, 110, 0.08);
    --user-bg: #1e2a14;
    --radius: 12px;
    --font-mono: 'DM Mono', monospace;
    --font-serif: 'Instrument Serif', Georgia, serif;
    --font-sans: 'DM Sans', system-ui, sans-serif;
  }

  * { margin: 0; padding: 0; box-sizing: border-box; }

  html, body {
    height: 100%;
    background: var(--bg);
    color: var(--text);
    font-family: var(--font-sans);
  }

  /* ── Layout ── */
  .app {
    display: flex;
    flex-direction: column;
    height: 100dvh;
    max-width: 860px;
    margin: 0 auto;
    overflow: hidden;
  }

  /* ── Header ── */
  header {
    padding: 20px 24px 16px;
    border-bottom: 1px solid var(--border);
    display: flex;
    align-items: center;
    justify-content: space-between;
    flex-shrink: 0;
  }

  .logo {
    font-family: var(--font-serif);
    font-size: 1.6rem;
    font-style: italic;
    letter-spacing: -0.02em;
    color: var(--text);
  }

  .logo span {
    color: var(--accent);
  }

  .header-right {
    display: flex;
    align-items: center;
    gap: 14px;
  }

  .header-meta {
    font-family: var(--font-mono);
    font-size: 0.7rem;
    color: var(--text-faint);
    letter-spacing: 0.06em;
    text-transform: uppercase;
  }

  .header-nav {
    font-family: var(--font-mono);
    font-size: 0.7rem;
    color: var(--text-faint);
    text-decoration: none;
    letter-spacing: 0.03em;
    transition: color 0.2s ease;
  }

  .header-nav:hover { color: var(--accent); }

  .github-link {
    color: var(--text-faint);
    transition: color 0.2s ease;
    display: flex;
    align-items: center;
  }

  .github-link:hover { color: var(--accent); }

  .github-link svg {
    width: 20px;
    height: 20px;
    fill: currentColor;
  }

  .gh-stats {
    display: flex;
    align-items: center;
    gap: 10px;
  }

  .gh-stat {
    display: flex;
    align-items: center;
    gap: 4px;
    font-family: var(--font-mono);
    font-size: 0.65rem;
    color: var(--text-faint);
    text-decoration: none;
    letter-spacing: 0.03em;
    transition: color 0.2s ease;
  }

  .gh-stat:hover { color: var(--accent); }

  .gh-stat svg {
    width: 13px;
    height: 13px;
    fill: currentColor;
  }

  /* ── Model Selector (shown before loading) ── */
  .model-selector {
    flex: 1;
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: safe center;
    padding: 40px 24px;
    gap: 32px;
    animation: fadeIn 0.6s ease;
    overflow-y: auto;
  }

  .model-selector::-webkit-scrollbar { width: 6px; background: transparent; }
  .model-selector::-webkit-scrollbar-track { background: transparent; }
  .model-selector::-webkit-scrollbar-thumb {
    background: transparent;
    border-radius: 4px;
    transition: background 0.2s;
  }
  .model-selector:hover::-webkit-scrollbar-thumb {
    background: var(--border);
  }
  .model-selector:hover::-webkit-scrollbar-thumb:hover {
    background: var(--text-faint);
  }

  .model-selector h2 {
    font-family: var(--font-serif);
    font-size: 2rem;
    font-weight: 400;
    text-align: center;
    line-height: 1.3;
  }

  .model-selector h2 em {
    color: var(--accent);
    font-style: italic;
  }

  .model-selector p {
    color: var(--text-dim);
    text-align: center;
    max-width: 480px;
    line-height: 1.6;
    font-size: 0.92rem;
  }

  .model-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(220px, 1fr));
    gap: 12px;
    width: 100%;
    max-width: 580px;
  }

  .model-card {
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: var(--radius);
    padding: 18px 20px;
    cursor: pointer;
    transition: all 0.25s ease;
    position: relative;
    overflow: hidden;
  }

  .model-card::before {
    content: '';
    position: absolute;
    inset: 0;
    background: linear-gradient(135deg, var(--accent-glow), transparent);
    opacity: 0;
    transition: opacity 0.25s ease;
  }

  .model-card:hover {
    border-color: var(--accent-dim);
    transform: translateY(-2px);
  }

  .model-card:hover::before { opacity: 1; }

  .model-card.selected {
    border-color: var(--accent);
    background: var(--user-bg);
  }

  .model-card.cached {
    border-style: dashed;
    border-color: var(--accent-dim);
  }

  .model-card.active-model {
    border-color: var(--accent);
    border-style: solid;
    background: var(--user-bg);
    box-shadow: 0 0 16px var(--accent-glow), inset 0 0 16px var(--accent-glow);
  }

  .model-card.active-model::before { opacity: 1; }

  .model-badge {
    position: absolute;
    top: 10px;
    right: 12px;
    font-family: var(--font-mono);
    font-size: 0.58rem;
    font-weight: 500;
    letter-spacing: 0.08em;
    text-transform: uppercase;
    padding: 2px 8px;
    border-radius: 100px;
    z-index: 1;
  }

  .cached-label {
    position: absolute;
    bottom: 10px;
    right: 12px;
    font-family: var(--font-mono);
    font-size: 0.52rem;
    font-weight: 500;
    letter-spacing: 0.06em;
    text-transform: uppercase;
    color: var(--accent-dim);
    opacity: 0.7;
    z-index: 1;
    cursor: pointer;
    transition: all 0.2s ease;
  }

  .cached-label:hover {
    color: #e08080;
    opacity: 1;
  }

  .tiny-label, .long-load-label, .goldilocks-label {
    font-family: var(--font-mono);
    font-size: 0.55rem;
    border-radius: 100px;
    padding: 1px 7px;
    margin-left: 6px;
    vertical-align: middle;
    letter-spacing: 0.06em;
    text-transform: uppercase;
    font-weight: 500;
  }

  .tiny-label {
    color: #b0a0d0;
    background: rgba(176, 160, 208, 0.1);
    border: 1px solid rgba(176, 160, 208, 0.2);
  }

  .long-load-label {
    color: #d0a070;
    background: rgba(208, 160, 112, 0.1);
    border: 1px solid rgba(208, 160, 112, 0.2);
  }

  .goldilocks-label {
    color: var(--accent);
    background: rgba(196, 240, 110, 0.1);
    border: 1px solid rgba(196, 240, 110, 0.2);
  }

  .model-tech {
    font-family: var(--font-mono);
    font-size: 0.62rem;
    color: var(--text-faint);
    margin-top: 6px;
    position: relative;
    letter-spacing: 0.02em;
  }

  .change-model-btn {
    display: none;
    font-family: var(--font-mono);
    font-size: 0.68rem;
    font-weight: 400;
    color: var(--text-dim);
    background: transparent;
    border: 1px solid var(--border);
    border-radius: 100px;
    padding: 6px 14px;
    cursor: pointer;
    letter-spacing: 0.04em;
    transition: all 0.2s ease;
  }

  .change-model-btn:hover {
    color: var(--accent);
    border-color: var(--accent-dim);
  }

  .model-card h3 {
    font-family: var(--font-mono);
    font-size: 0.82rem;
    font-weight: 500;
    color: var(--text);
    margin-bottom: 6px;
    position: relative;
  }

  .model-card .model-desc {
    font-size: 0.78rem;
    color: var(--text-dim);
    line-height: 1.4;
    position: relative;
  }

  .model-card .model-size {
    font-family: var(--font-mono);
    font-size: 0.68rem;
    color: var(--accent-dim);
    margin-top: 8px;
    position: relative;
  }

  .model-card .model-time {
    font-size: 0.72rem;
    color: var(--text-faint);
    margin-top: 4px;
    position: relative;
  }

  .download-notice {
    max-width: 520px;
    text-align: center;
    display: flex;
    flex-direction: column;
    gap: 8px;
  }

  .download-notice .notice-main {
    font-size: 0.82rem;
    color: var(--text-dim);
    line-height: 1.5;
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: var(--radius);
    padding: 14px 20px;
  }

  .download-notice .notice-main svg {
    width: 14px;
    height: 14px;
    fill: var(--accent-dim);
    vertical-align: -2px;
    margin-right: 4px;
  }

  .download-notice .notice-detail {
    font-family: var(--font-mono);
    font-size: 0.68rem;
    color: var(--text-faint);
    letter-spacing: 0.03em;
  }

  /* ── Loading Screen Enhancements ── */
  .loading-phases {
    display: flex;
    gap: 24px;
    margin-top: 4px;
  }

  .phase {
    display: flex;
    align-items: center;
    gap: 6px;
    font-family: var(--font-mono);
    font-size: 0.7rem;
    color: var(--text-faint);
    letter-spacing: 0.03em;
  }

  .phase.active { color: var(--accent); }
  .phase.done { color: var(--accent-dim); }

  .phase-dot {
    width: 7px;
    height: 7px;
    border-radius: 50%;
    background: var(--border);
    flex-shrink: 0;
  }

  .phase.active .phase-dot {
    background: var(--accent);
    box-shadow: 0 0 8px var(--accent-glow);
    animation: pulse 1.5s ease infinite;
  }

  .phase.done .phase-dot { background: var(--accent-dim); }

  @keyframes pulse {
    0%, 100% { opacity: 1; }
    50% { opacity: 0.4; }
  }

  .loading-stats {
    display: flex;
    gap: 20px;
    font-family: var(--font-mono);
    font-size: 0.7rem;
    color: var(--text-faint);
    letter-spacing: 0.03em;
  }

  .loading-stats span strong {
    color: var(--text-dim);
    font-weight: 500;
  }

  .loading-model-name {
    font-family: var(--font-serif);
    font-style: italic;
    font-size: 1.2rem;
    color: var(--text-dim);
  }

  .loading-tip {
    font-size: 0.78rem;
    color: var(--text-faint);
    text-align: center;
    max-width: 380px;
    line-height: 1.5;
    margin-top: 8px;
    transition: opacity 0.3s ease;
  }

  .webgpu-warning {
    background: #2a1a1a;
    border: 1px solid #5a2a2a;
    border-radius: var(--radius);
    padding: 16px 20px;
    max-width: 480px;
    text-align: center;
    font-size: 0.85rem;
    color: #e8a0a0;
    line-height: 1.5;
  }

  .network-error {
    background: #2a1a1a;
    border: 1px solid #5a2a2a;
    border-radius: var(--radius);
    padding: 20px 24px;
    max-width: 520px;
    text-align: left;
    font-size: 0.82rem;
    color: #e8a0a0;
    line-height: 1.6;
  }

  .network-error strong {
    display: block;
    margin-bottom: 8px;
    font-size: 0.9rem;
  }

  .network-error code {
    font-family: var(--font-mono);
    font-size: 0.72rem;
    background: rgba(255, 255, 255, 0.06);
    padding: 2px 6px;
    border-radius: 4px;
  }

  .network-error ul {
    margin: 8px 0;
    padding-left: 18px;
  }

  .network-error li {
    margin: 4px 0;
  }

  /* ── Architecture Section ── */
  .arch-link {
    font-family: var(--font-mono);
    font-size: 0.72rem;
    color: var(--text-faint);
    letter-spacing: 0.03em;
    text-decoration: none;
    transition: color 0.2s ease;
  }

  .arch-link:hover { color: var(--accent); }

  .arch-section {
    width: 100%;
    max-width: 580px;
    margin-top: 8px;
    padding-top: 32px;
    border-top: 1px solid var(--border);
  }

  .arch-section h3 {
    font-family: var(--font-serif);
    font-size: 1.3rem;
    font-weight: 400;
    color: var(--text);
    margin-bottom: 20px;
    text-align: center;
  }

  .arch-columns {
    display: grid;
    grid-template-columns: 1fr 1fr;
    gap: 16px;
  }

  @media (max-width: 600px) {
    .arch-columns { grid-template-columns: 1fr; }
  }

  .arch-card {
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: var(--radius);
    padding: 20px;
  }

  .arch-card h4 {
    font-family: var(--font-mono);
    font-size: 0.78rem;
    font-weight: 500;
    color: var(--accent);
    margin-bottom: 12px;
    letter-spacing: 0.03em;
  }

  .arch-card p {
    font-size: 0.82rem;
    color: var(--text-dim);
    line-height: 1.6;
    text-align: left;
    margin-bottom: 12px;
  }

  .arch-card p:last-child { margin-bottom: 0; }

  .arch-card .arch-label {
    font-family: var(--font-mono);
    font-size: 0.65rem;
    color: var(--text-faint);
    letter-spacing: 0.05em;
    text-transform: uppercase;
    margin-bottom: 4px;
  }

  .arch-card ul {
    list-style: none;
    padding: 0;
    margin: 0 0 12px;
  }

  .arch-card li {
    font-size: 0.78rem;
    color: var(--text-dim);
    line-height: 1.5;
    padding-left: 14px;
    position: relative;
  }

  .arch-card li::before {
    content: '·';
    position: absolute;
    left: 2px;
    color: var(--text-faint);
    font-weight: bold;
  }

  .arch-flow {
    display: flex;
    flex-direction: column;
    align-items: center;
    margin-bottom: 20px;
    padding: 16px 12px;
    background: var(--bg);
    border-radius: 10px;
    border: 1px solid var(--border);
  }

  .arch-flow-step {
    width: 100%;
    background: var(--surface-2);
    border: 1px solid var(--border);
    border-radius: 8px;
    padding: 9px 12px;
    text-align: center;
    font-family: var(--font-mono);
    font-size: 0.68rem;
    font-weight: 400;
    color: var(--text-dim);
    letter-spacing: 0.02em;
    line-height: 1.4;
  }

  .arch-flow-step .step-sub {
    display: block;
    font-size: 0.58rem;
    color: var(--text-faint);
    font-weight: 300;
    margin-top: 2px;
    letter-spacing: 0.03em;
  }

  .arch-flow-step.highlight {
    border-color: var(--accent-dim);
    background: rgba(196, 240, 110, 0.04);
    color: var(--accent);
  }

  .arch-flow-step.highlight .step-sub {
    color: var(--accent-dim);
  }

  .arch-flow-step.step-end {
    background: transparent;
    border-style: dashed;
    color: var(--text-faint);
  }

  .arch-flow-step.step-fork {
    display: flex;
    justify-content: center;
    gap: 6px;
    background: transparent;
    border: none;
    padding: 0;
  }

  .arch-flow-step.step-fork .fork-option {
    flex: 1;
    background: var(--surface-2);
    border: 1px solid var(--border);
    border-radius: 8px;
    padding: 8px 6px;
    font-family: var(--font-mono);
    font-size: 0.62rem;
    color: var(--text-dim);
    text-align: center;
  }

  .arch-flow-step.step-fork .fork-primary {
    border-color: var(--accent-dim);
    color: var(--accent-dim);
  }

  .arch-flow-arrow {
    display: flex;
    align-items: center;
    justify-content: center;
    padding: 4px 0;
    color: var(--border);
  }

  .arch-flow-arrow svg {
    width: 12px;
    height: 18px;
  }

  .arch-shared {
    margin-top: 16px;
    text-align: center;
    font-family: var(--font-mono);
    font-size: 0.68rem;
    color: var(--text-faint);
    letter-spacing: 0.03em;
    line-height: 1.6;
  }

  .load-btn {
    font-family: var(--font-mono);
    font-size: 0.85rem;
    font-weight: 500;
    background: var(--accent);
    color: var(--bg);
    border: none;
    border-radius: 100px;
    padding: 14px 40px;
    cursor: pointer;
    letter-spacing: 0.04em;
    text-transform: uppercase;
    transition: all 0.2s ease;
  }

  .load-btn:hover { transform: scale(1.03); filter: brightness(1.1); }
  .load-btn:disabled {
    opacity: 0.4;
    cursor: not-allowed;
    transform: none;
    filter: none;
  }

  /* ── Loading Screen ── */
  .loading-screen {
    flex: 1;
    display: none;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    padding: 40px 24px;
    gap: 24px;
    animation: fadeIn 0.4s ease;
  }

  .loading-screen.active { display: flex; }

  .loader-ring {
    width: 56px;
    height: 56px;
    border-radius: 50%;
    border: 2px solid var(--border);
    border-top-color: var(--accent);
    animation: spin 1s linear infinite;
  }

  .loading-label {
    font-family: var(--font-mono);
    font-size: 0.78rem;
    color: var(--text-dim);
    text-align: center;
    letter-spacing: 0.04em;
  }

  .progress-bar-container {
    width: 100%;
    max-width: 400px;
    height: 4px;
    background: var(--surface-2);
    border-radius: 4px;
    overflow: hidden;
  }

  .progress-bar {
    height: 100%;
    background: var(--accent);
    width: 0%;
    border-radius: 4px;
    transition: width 0.3s ease;
  }

  /* ── Chat Area ── */
  .chat-container {
    flex: 1;
    display: none;
    flex-direction: column;
    overflow: hidden;
    animation: fadeIn 0.4s ease;
  }

  .chat-container.active { display: flex; }

  .messages {
    flex: 1;
    overflow-y: auto;
    padding: 20px 24px;
    display: flex;
    flex-direction: column;
    gap: 4px;
    scroll-behavior: smooth;
  }

  .messages::-webkit-scrollbar { width: 6px; background: transparent; }
  .messages::-webkit-scrollbar-track { background: transparent; }
  .messages::-webkit-scrollbar-thumb {
    background: transparent;
    border-radius: 4px;
    transition: background 0.2s;
  }
  .messages:hover::-webkit-scrollbar-thumb {
    background: var(--border);
  }
  .messages:hover::-webkit-scrollbar-thumb:hover {
    background: var(--text-faint);
  }

  .message {
    max-width: 85%;
    padding: 12px 18px;
    border-radius: var(--radius);
    font-size: 0.92rem;
    line-height: 1.65;
    animation: msgIn 0.3s ease;
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .message.user {
    align-self: flex-end;
    background: var(--user-bg);
    border: 1px solid #2a3a1a;
    color: var(--text);
    border-bottom-right-radius: 4px;
  }

  .message.assistant {
    align-self: flex-start;
    background: var(--surface);
    border: 1px solid var(--border);
    color: var(--text);
    border-bottom-left-radius: 4px;
  }

  .message.system {
    align-self: center;
    background: transparent;
    color: var(--text-faint);
    font-family: var(--font-mono);
    font-size: 0.72rem;
    padding: 8px 0;
    letter-spacing: 0.04em;
    text-transform: uppercase;
  }

  .typing-indicator {
    display: none;
    align-self: flex-start;
    padding: 14px 20px;
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: var(--radius);
    border-bottom-left-radius: 4px;
    gap: 5px;
  }

  .typing-indicator.active { display: flex; }

  .typing-dot {
    width: 6px;
    height: 6px;
    border-radius: 50%;
    background: var(--text-faint);
    animation: bounce 1.2s infinite;
  }

  .typing-dot:nth-child(2) { animation-delay: 0.15s; }
  .typing-dot:nth-child(3) { animation-delay: 0.3s; }

  /* ── Input Area ── */
  .input-area {
    padding: 16px 24px 24px;
    border-top: 1px solid var(--border);
    flex-shrink: 0;
  }

  .input-row {
    display: flex;
    gap: 10px;
    align-items: flex-end;
  }

  .input-wrapper {
    flex: 1;
    position: relative;
  }

  textarea {
    width: 100%;
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: var(--radius);
    padding: 14px 18px;
    color: var(--text);
    font-family: var(--font-sans);
    font-size: 0.92rem;
    resize: none;
    outline: none;
    line-height: 1.5;
    min-height: 50px;
    max-height: 150px;
    transition: border-color 0.2s ease;
  }

  textarea::placeholder { color: var(--text-faint); }
  textarea:focus { border-color: var(--accent-dim); }

  .send-btn {
    width: 48px;
    height: 48px;
    border-radius: 50%;
    background: var(--accent);
    border: none;
    cursor: pointer;
    display: flex;
    align-items: center;
    justify-content: center;
    flex-shrink: 0;
    transition: all 0.2s ease;
  }

  .send-btn:hover { transform: scale(1.06); filter: brightness(1.1); }
  .send-btn:disabled { opacity: 0.3; cursor: not-allowed; transform: none; filter: none; }

  .send-btn svg {
    width: 20px;
    height: 20px;
    fill: var(--bg);
  }

  .input-meta {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-top: 8px;
    font-family: var(--font-mono);
    font-size: 0.65rem;
    color: var(--text-faint);
    letter-spacing: 0.04em;
  }

  .input-meta-left {
    display: flex;
    align-items: center;
    gap: 10px;
  }

  .input-meta-right {
    display: flex;
    align-items: center;
    gap: 12px;
  }

  /* ── Chat Toolbar Buttons ── */
  .toolbar-btn {
    font-family: var(--font-mono);
    font-size: 0.62rem;
    color: var(--text-faint);
    background: none;
    border: 1px solid transparent;
    border-radius: 6px;
    padding: 3px 8px;
    cursor: pointer;
    letter-spacing: 0.03em;
    transition: all 0.2s ease;
    display: flex;
    align-items: center;
    gap: 4px;
  }

  .toolbar-btn:hover {
    color: var(--text-dim);
    border-color: var(--border);
    background: var(--surface);
  }

  .toolbar-btn.active {
    color: var(--accent);
    border-color: var(--accent-dim);
    background: rgba(196, 240, 110, 0.04);
  }

  .toolbar-btn svg { width: 12px; height: 12px; fill: currentColor; flex-shrink: 0; }

  /* ── Settings Panel ── */
  .settings-panel {
    display: none;
    border-bottom: 1px solid var(--border);
    padding: 16px 24px;
    background: var(--surface);
    animation: fadeIn 0.2s ease;
    flex-shrink: 0;
    max-height: 400px;
    overflow-y: auto;
  }

  .settings-panel.active { display: block; }

  .settings-grid {
    display: grid;
    grid-template-columns: 1fr 1fr 1fr;
    gap: 16px;
  }

  @media (max-width: 900px) {
    .settings-grid { grid-template-columns: 1fr 1fr; }
  }

  @media (max-width: 600px) {
    .settings-grid { grid-template-columns: 1fr; }
  }

  .settings-section h4 {
    font-family: var(--font-mono);
    font-size: 0.68rem;
    font-weight: 500;
    color: var(--text-dim);
    letter-spacing: 0.04em;
    text-transform: uppercase;
    margin-bottom: 10px;
  }

  .settings-field {
    margin-bottom: 10px;
  }

  .settings-field label {
    display: flex;
    justify-content: space-between;
    font-family: var(--font-mono);
    font-size: 0.65rem;
    color: var(--text-faint);
    margin-bottom: 5px;
    letter-spacing: 0.02em;
  }

  .settings-field label .val {
    color: var(--text-dim);
    font-weight: 500;
  }

  .settings-field input[type="range"] {
    width: 100%;
    height: 4px;
    -webkit-appearance: none;
    appearance: none;
    background: var(--border);
    border-radius: 4px;
    outline: none;
  }

  .settings-field input[type="range"]::-webkit-slider-thumb {
    -webkit-appearance: none;
    width: 14px;
    height: 14px;
    border-radius: 50%;
    background: var(--accent);
    cursor: pointer;
  }

  .preset-select, .system-prompt-input {
    width: 100%;
    background: var(--bg);
    border: 1px solid var(--border);
    border-radius: 8px;
    color: var(--text);
    font-family: var(--font-sans);
    font-size: 0.82rem;
    outline: none;
    transition: border-color 0.2s ease;
  }

  .preset-select:focus, .system-prompt-input:focus {
    border-color: var(--accent-dim);
  }

  .preset-select {
    padding: 8px 10px;
    margin-bottom: 8px;
    font-size: 0.78rem;
  }

  .preset-select option {
    background: var(--surface);
    color: var(--text);
  }

  .system-prompt-input {
    padding: 10px 12px;
    min-height: 64px;
    max-height: 120px;
    resize: vertical;
    line-height: 1.4;
  }

  /* ── Knowledge Base ── */
  .kb-section {
    display: flex;
    flex-direction: column;
    gap: 10px;
  }

  .kb-header {
    display: flex;
    align-items: center;
    justify-content: space-between;
  }

  .kb-toggle {
    position: relative;
    width: 36px;
    height: 20px;
    flex-shrink: 0;
  }

  .kb-toggle input {
    opacity: 0;
    width: 0;
    height: 0;
  }

  .kb-toggle-slider {
    position: absolute;
    inset: 0;
    background: var(--border);
    border-radius: 20px;
    cursor: pointer;
    transition: background 0.2s ease;
  }

  .kb-toggle-slider::before {
    content: '';
    position: absolute;
    width: 14px;
    height: 14px;
    left: 3px;
    bottom: 3px;
    background: var(--text-dim);
    border-radius: 50%;
    transition: transform 0.2s ease, background 0.2s ease;
  }

  .kb-toggle input:checked + .kb-toggle-slider {
    background: var(--accent-dim);
  }

  .kb-toggle input:checked + .kb-toggle-slider::before {
    transform: translateX(16px);
    background: var(--accent);
  }

  .kb-model-status {
    font-family: var(--font-mono);
    font-size: 0.68rem;
    color: var(--text-faint);
    display: flex;
    align-items: center;
    gap: 8px;
  }

  .kb-model-status .status-dot {
    width: 6px;
    height: 6px;
    border-radius: 50%;
    background: var(--text-faint);
    flex-shrink: 0;
  }

  .kb-model-status .status-dot.loaded {
    background: var(--accent);
  }

  .kb-model-status .status-dot.loading {
    background: #d0a070;
    animation: pulse 1s ease infinite;
  }

  @keyframes pulse {
    0%, 100% { opacity: 1; }
    50% { opacity: 0.4; }
  }

  .kb-load-btn {
    font-family: var(--font-mono);
    font-size: 0.65rem;
    color: var(--accent);
    background: none;
    border: 1px solid var(--accent-dim);
    border-radius: 6px;
    padding: 2px 8px;
    cursor: pointer;
    transition: all 0.2s ease;
  }

  .kb-load-btn:hover {
    background: var(--accent-glow);
  }

  .kb-actions {
    display: flex;
    gap: 8px;
  }

  .kb-upload-btn, .kb-clear-btn {
    flex: 1;
    font-family: var(--font-mono);
    font-size: 0.72rem;
    letter-spacing: 0.03em;
    padding: 7px 12px;
    border-radius: 8px;
    cursor: pointer;
    transition: all 0.2s ease;
    text-align: center;
  }

  .kb-upload-btn {
    background: var(--accent-glow);
    border: 1px solid var(--accent-dim);
    color: var(--accent);
  }

  .kb-upload-btn:hover {
    background: rgba(196, 240, 110, 0.15);
    border-color: var(--accent);
  }

  .kb-clear-btn {
    background: none;
    border: 1px solid var(--border);
    color: var(--text-faint);
  }

  .kb-clear-btn:hover {
    border-color: #e05050;
    color: #e05050;
  }

  .kb-docs {
    display: flex;
    flex-direction: column;
    gap: 4px;
    max-height: 180px;
    overflow-y: auto;
  }

  .kb-docs::-webkit-scrollbar { width: 4px; }
  .kb-docs::-webkit-scrollbar-thumb { background: var(--border); border-radius: 4px; }

  .kb-doc-item {
    display: flex;
    align-items: center;
    gap: 8px;
    padding: 6px 8px;
    background: var(--bg);
    border: 1px solid var(--border);
    border-radius: 6px;
    font-family: var(--font-mono);
    font-size: 0.68rem;
  }

  .kb-doc-item .doc-name {
    flex: 1;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
    color: var(--text);
  }

  .kb-doc-item .doc-meta {
    color: var(--text-faint);
    font-size: 0.6rem;
    white-space: nowrap;
  }

  .kb-doc-item .doc-remove {
    background: none;
    border: none;
    color: var(--text-faint);
    cursor: pointer;
    padding: 0 2px;
    font-size: 0.8rem;
    line-height: 1;
    transition: color 0.2s ease;
  }

  .kb-doc-item .doc-remove:hover {
    color: #e05050;
  }

  .kb-empty {
    font-family: var(--font-mono);
    font-size: 0.68rem;
    color: var(--text-faint);
    text-align: center;
    padding: 8px;
  }

  .kb-loading-overlay {
    display: none;
    position: fixed;
    inset: 0;
    z-index: 200;
    background: rgba(12, 12, 14, 0.92);
    align-items: center;
    justify-content: center;
    flex-direction: column;
    gap: 16px;
    animation: fadeIn 0.2s ease;
  }

  .kb-loading-overlay.active {
    display: flex;
  }

  .kb-loading-overlay .kb-loading-title {
    font-family: var(--font-serif);
    font-size: 1.3rem;
    font-style: italic;
    color: var(--text);
  }

  .kb-loading-overlay .kb-loading-subtitle {
    font-family: var(--font-mono);
    font-size: 0.75rem;
    color: var(--text-dim);
    text-align: center;
    max-width: 400px;
  }

  .kb-loading-overlay .kb-loading-bar {
    width: 240px;
    height: 4px;
    background: var(--border);
    border-radius: 4px;
    overflow: hidden;
  }

  .kb-loading-overlay .kb-loading-bar-fill {
    height: 100%;
    width: 0%;
    background: var(--accent);
    border-radius: 4px;
    transition: width 0.3s ease;
  }

  .kb-loading-overlay .kb-loading-text {
    font-family: var(--font-mono);
    font-size: 0.68rem;
    color: var(--text-faint);
  }

  .kb-rag-indicator {
    font-family: var(--font-mono);
    font-size: 0.68rem;
    color: var(--accent-dim);
    padding: 4px 10px;
    background: var(--accent-glow);
    border-radius: 6px;
    margin-bottom: 4px;
  }

  /* ── Stop Button ── */
  .stop-btn {
    width: 48px;
    height: 48px;
    border-radius: 50%;
    background: #e05050;
    border: none;
    cursor: pointer;
    display: none;
    align-items: center;
    justify-content: center;
    flex-shrink: 0;
    transition: all 0.2s ease;
  }

  .stop-btn.active { display: flex; }
  .stop-btn:hover { transform: scale(1.06); filter: brightness(1.1); }

  .stop-btn svg {
    width: 16px;
    height: 16px;
    fill: white;
  }

  /* ── File Upload ── */
  .file-btn {
    width: 40px;
    height: 40px;
    border-radius: 50%;
    background: transparent;
    border: 1px solid var(--border);
    cursor: pointer;
    display: flex;
    align-items: center;
    justify-content: center;
    flex-shrink: 0;
    transition: all 0.2s ease;
    color: var(--text-faint);
  }

  .file-btn:hover {
    border-color: var(--accent-dim);
    color: var(--accent);
    background: var(--surface);
  }

  .file-btn svg { width: 16px; height: 16px; fill: currentColor; }

  .file-drop-overlay {
    display: none;
    position: absolute;
    inset: 0;
    background: rgba(12, 12, 14, 0.92);
    z-index: 10;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    gap: 12px;
    border: 2px dashed var(--accent-dim);
    border-radius: var(--radius);
    margin: 8px;
    pointer-events: none;
  }

  .file-drop-overlay.active { display: flex; }

  .file-drop-overlay svg { width: 40px; height: 40px; fill: var(--accent-dim); }

  .file-drop-overlay span {
    font-family: var(--font-mono);
    font-size: 0.82rem;
    color: var(--accent-dim);
    letter-spacing: 0.03em;
  }

  /* ── Conversations Modal ── */
  .conv-modal {
    display: none;
    position: fixed;
    inset: 0;
    z-index: 100;
    background: rgba(12, 12, 14, 0.85);
    align-items: center;
    justify-content: center;
    animation: fadeIn 0.2s ease;
  }

  .conv-modal.active { display: flex; }

  .conv-modal-inner {
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: var(--radius);
    width: 90%;
    max-width: 480px;
    max-height: 70vh;
    display: flex;
    flex-direction: column;
    overflow: hidden;
  }

  .conv-modal-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    padding: 16px 20px;
    border-bottom: 1px solid var(--border);
  }

  .conv-modal-header h3 {
    font-family: var(--font-mono);
    font-size: 0.82rem;
    font-weight: 500;
    color: var(--text);
  }

  .conv-modal-close {
    background: none;
    border: none;
    color: var(--text-faint);
    cursor: pointer;
    font-size: 1.2rem;
    padding: 4px;
    line-height: 1;
    transition: color 0.2s;
  }

  .conv-modal-close:hover { color: var(--text); }

  .conv-list {
    flex: 1;
    overflow-y: auto;
    padding: 8px;
  }

  .conv-list::-webkit-scrollbar { width: 4px; }
  .conv-list::-webkit-scrollbar-thumb { background: var(--border); border-radius: 4px; }

  .conv-item {
    display: flex;
    justify-content: space-between;
    align-items: center;
    padding: 12px 14px;
    border-radius: 8px;
    cursor: pointer;
    transition: background 0.15s ease;
  }

  .conv-item:hover { background: var(--surface-2); }

  .conv-item-info { flex: 1; min-width: 0; }

  .conv-item-title {
    font-size: 0.82rem;
    color: var(--text);
    white-space: nowrap;
    overflow: hidden;
    text-overflow: ellipsis;
  }

  .conv-item-meta {
    font-family: var(--font-mono);
    font-size: 0.62rem;
    color: var(--text-faint);
    margin-top: 3px;
  }

  .conv-item-delete {
    background: none;
    border: none;
    color: var(--text-faint);
    cursor: pointer;
    padding: 4px 8px;
    font-size: 0.72rem;
    border-radius: 4px;
    transition: all 0.15s;
    flex-shrink: 0;
  }

  .conv-item-delete:hover { color: #e05050; background: rgba(224, 80, 80, 0.1); }

  .conv-empty {
    text-align: center;
    padding: 32px 16px;
    color: var(--text-faint);
    font-size: 0.82rem;
  }

  /* ── Token Context Bar ── */
  .token-bar {
    display: flex;
    align-items: center;
    gap: 6px;
  }

  .token-bar-track {
    width: 48px;
    height: 3px;
    background: var(--border);
    border-radius: 3px;
    overflow: hidden;
  }

  .token-bar-fill {
    height: 100%;
    background: var(--accent-dim);
    border-radius: 3px;
    transition: width 0.3s ease, background 0.3s ease;
  }

  .token-bar-fill.warn { background: #d0a070; }
  .token-bar-fill.danger { background: #e05050; }

  /* ── Markdown in Messages ── */
  .message.assistant.rendered { white-space: normal; }

  .message.assistant.rendered p { margin: 0 0 0.6em; }
  .message.assistant.rendered p:last-child { margin-bottom: 0; }

  .message.assistant.rendered h1,
  .message.assistant.rendered h2,
  .message.assistant.rendered h3 {
    font-family: var(--font-mono);
    font-weight: 500;
    color: var(--text);
    margin: 0.8em 0 0.4em;
    line-height: 1.3;
  }

  .message.assistant.rendered h1 { font-size: 1rem; }
  .message.assistant.rendered h2 { font-size: 0.92rem; }
  .message.assistant.rendered h3 { font-size: 0.86rem; }

  .message.assistant.rendered code {
    font-family: var(--font-mono);
    font-size: 0.82em;
    background: rgba(255, 255, 255, 0.06);
    padding: 1px 5px;
    border-radius: 4px;
    color: var(--accent);
  }

  .message.assistant.rendered pre {
    background: var(--bg);
    border: 1px solid var(--border);
    border-radius: 8px;
    padding: 12px 14px;
    margin: 0.6em 0;
    overflow-x: auto;
  }

  .message.assistant.rendered pre code {
    background: none;
    padding: 0;
    color: var(--text-dim);
    font-size: 0.78rem;
    line-height: 1.5;
  }

  .message.assistant.rendered ul,
  .message.assistant.rendered ol {
    padding-left: 1.4em;
    margin: 0.4em 0;
  }

  .message.assistant.rendered li { margin: 0.2em 0; }

  .message.assistant.rendered blockquote {
    border-left: 3px solid var(--accent-dim);
    padding-left: 12px;
    margin: 0.6em 0;
    color: var(--text-dim);
    font-style: italic;
  }

  .message.assistant.rendered a {
    color: var(--accent);
    text-decoration: underline;
    text-underline-offset: 2px;
  }

  .message.assistant.rendered strong { color: var(--text); }

  .message.assistant.rendered hr {
    border: none;
    border-top: 1px solid var(--border);
    margin: 0.8em 0;
  }

  .message.file-context {
    align-self: center;
    background: var(--surface);
    border: 1px dashed var(--border);
    color: var(--text-dim);
    font-family: var(--font-mono);
    font-size: 0.72rem;
    padding: 8px 14px;
    border-radius: var(--radius);
  }

  /* ── Animations ── */
  @keyframes fadeIn {
    from { opacity: 0; transform: translateY(8px); }
    to { opacity: 1; transform: translateY(0); }
  }

  @keyframes spin {
    to { transform: rotate(360deg); }
  }

  @keyframes bounce {
    0%, 60%, 100% { transform: translateY(0); }
    30% { transform: translateY(-6px); }
  }

  @keyframes msgIn {
    from { opacity: 0; transform: translateY(6px); }
    to { opacity: 1; transform: translateY(0); }
  }

  /* ── Responsive ── */
  @media (max-width: 600px) {
    header { padding: 16px 16px 12px; }
    .messages { padding: 16px; }
    .input-area { padding: 12px 16px 20px; }
    .model-selector h2 { font-size: 1.5rem; }
    .model-grid { grid-template-columns: 1fr; }
    .message { max-width: 92%; }
  }
</style>
</head>
<body>

<div class="app">
  <header>
    <div class="logo">Think<span>Here</span></div>
    <div class="header-right">
      <a class="header-nav" href="#models">Models</a>
      <a class="header-nav" href="#architecture">How It Works</a>
      <button class="change-model-btn" id="changeModelBtn" onclick="showModelSelector()">Change Model</button>
      <div class="header-meta" id="headerStatus"></div>
      <div class="gh-stats">
        <a class="gh-stat" href="https://github.com/ipattis/thinkhere/stargazers" target="_blank" rel="noopener noreferrer" aria-label="GitHub stars">
          <svg viewBox="0 0 16 16"><path d="M8 .25a.75.75 0 01.673.418l1.882 3.815 4.21.612a.75.75 0 01.416 1.279l-3.046 2.97.719 4.192a.75.75 0 01-1.088.791L8 12.347l-3.766 1.98a.75.75 0 01-1.088-.79l.72-4.194L.818 6.374a.75.75 0 01.416-1.28l4.21-.611L7.327.668A.75.75 0 018 .25z"/></svg>
          <span id="ghStars"></span>
        </a>
        <a class="gh-stat" href="https://github.com/ipattis/thinkhere/fork" target="_blank" rel="noopener noreferrer" aria-label="GitHub forks">
          <svg viewBox="0 0 16 16"><path d="M5 3.25a.75.75 0 11-1.5 0 .75.75 0 011.5 0zm0 2.122a2.25 2.25 0 10-1.5 0v.878A2.25 2.25 0 005.75 8.5h1.5v2.128a2.251 2.251 0 101.5 0V8.5h1.5a2.25 2.25 0 002.25-2.25v-.878a2.25 2.25 0 10-1.5 0v.878a.75.75 0 01-.75.75h-4.5A.75.75 0 015 6.25v-.878zm3.75 7.378a.75.75 0 11-1.5 0 .75.75 0 011.5 0zm3-8.75a.75.75 0 100-1.5.75.75 0 000 1.5z"/></svg>
          <span id="ghForks"></span>
        </a>
        <a class="github-link" href="https://github.com/ipattis/thinkhere" target="_blank" rel="noopener noreferrer" aria-label="View source on GitHub">
          <svg viewBox="0 0 16 16"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"/></svg>
        </a>
      </div>
    </div>
  </header>

  <!-- Model Selection -->
  <div class="model-selector" id="modelSelector">
    <h2 id="models">Run AI <em>entirely</em> in your browser</h2>
    <p>No servers, no API keys, no data leaves your device. Powered by WebLLM and Transformers.js — everything runs locally on your hardware.</p>

    <div id="webgpuCheck"></div>

    <div class="model-grid" id="modelGrid"></div>

    <div class="download-notice">
      <div class="notice-main">
        <svg viewBox="0 0 24 24"><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"/></svg>
        First load downloads model weights to your browser — this is a <strong>one-time download</strong>. After that, the model loads from cache in seconds.
      </div>
      <div class="notice-detail">WebLLM models require WebGPU (Chrome 113+, Edge 113+). Transformers.js models use ONNX Runtime Web. All need network access to huggingface.co</div>
    </div>

    <a class="arch-link" href="#architecture">How do these models run in your browser? &darr;</a>

    <button class="load-btn" id="loadBtn" disabled onclick="loadModel()">Select a model</button>

    <!-- Architecture Explainer -->
    <div class="arch-section" id="architecture">
      <h3>Two paths to in-browser AI</h3>
      <div class="arch-columns">
        <div class="arch-card">
          <h4>WebLLM + MLC</h4>
          <div class="arch-flow">
            <div class="arch-flow-step">HuggingFace<span class="step-sub">MLC-format weights</span></div>
            <div class="arch-flow-arrow"><svg viewBox="0 0 12 18"><line x1="6" y1="0" x2="6" y2="12" stroke="currentColor" stroke-width="1.5"/><polyline points="2.5,9.5 6,14 9.5,9.5" fill="none" stroke="currentColor" stroke-width="1.5"/></svg></div>
            <div class="arch-flow-step highlight">TVM / MLC Compiler<span class="step-sub">Ahead-of-time compilation</span></div>
            <div class="arch-flow-arrow"><svg viewBox="0 0 12 18"><line x1="6" y1="0" x2="6" y2="12" stroke="currentColor" stroke-width="1.5"/><polyline points="2.5,9.5 6,14 9.5,9.5" fill="none" stroke="currentColor" stroke-width="1.5"/></svg></div>
            <div class="arch-flow-step">WebGPU Compute Shaders<span class="step-sub">Pre-optimized GPU kernels</span></div>
            <div class="arch-flow-arrow"><svg viewBox="0 0 12 18"><line x1="6" y1="0" x2="6" y2="12" stroke="currentColor" stroke-width="1.5"/><polyline points="2.5,9.5 6,14 9.5,9.5" fill="none" stroke="currentColor" stroke-width="1.5"/></svg></div>
            <div class="arch-flow-step step-end">Your GPU</div>
          </div>
          <p>Models are compiled ahead-of-time using <strong>Apache TVM / MLC</strong> (Machine Learning Compilation). The compiler transforms model weights and operations into optimized <strong>WebGPU compute shaders</strong> that run directly on your GPU.</p>
          <div class="arch-label">Trade-offs</div>
          <ul>
            <li>Fast inference — kernels are pre-optimized</li>
            <li>First run compiles shaders for your GPU (cached after)</li>
            <li>Model must be specifically compiled for MLC</li>
          </ul>
          <p class="arch-label">Used by</p>
          <p>SmolLM2 360M, SmolLM2 1.7B, Llama 3.2 1B, Phi-3.5 Mini</p>
        </div>
        <div class="arch-card">
          <h4>Transformers.js + ONNX Runtime Web</h4>
          <div class="arch-flow">
            <div class="arch-flow-step">HuggingFace<span class="step-sub">ONNX-format model graph + weights</span></div>
            <div class="arch-flow-arrow"><svg viewBox="0 0 12 18"><line x1="6" y1="0" x2="6" y2="12" stroke="currentColor" stroke-width="1.5"/><polyline points="2.5,9.5 6,14 9.5,9.5" fill="none" stroke="currentColor" stroke-width="1.5"/></svg></div>
            <div class="arch-flow-step highlight">ONNX Runtime Web<span class="step-sub">Builds execution plan at load time</span></div>
            <div class="arch-flow-arrow"><svg viewBox="0 0 12 18"><line x1="6" y1="0" x2="6" y2="12" stroke="currentColor" stroke-width="1.5"/><polyline points="2.5,9.5 6,14 9.5,9.5" fill="none" stroke="currentColor" stroke-width="1.5"/></svg></div>
            <div class="arch-flow-step step-fork">
              <div class="fork-option fork-primary">WebGPU</div>
              <div class="fork-option">WASM fallback</div>
            </div>
            <div class="arch-flow-arrow"><svg viewBox="0 0 12 18"><line x1="6" y1="0" x2="6" y2="12" stroke="currentColor" stroke-width="1.5"/><polyline points="2.5,9.5 6,14 9.5,9.5" fill="none" stroke="currentColor" stroke-width="1.5"/></svg></div>
            <div class="arch-flow-step step-end">Your GPU / CPU</div>
          </div>
          <p>Models are stored in the standard <strong>ONNX</strong> (Open Neural Network Exchange) format. <strong>ONNX Runtime Web</strong> interprets the model graph at load time and executes it on your GPU via WebGPU, or falls back to WebAssembly on unsupported hardware.</p>
          <div class="arch-label">Trade-offs</div>
          <ul>
            <li>Supports any model exportable to ONNX</li>
            <li>Can fall back to WASM if WebGPU is unavailable</li>
            <li>Slightly more overhead than pre-compiled kernels</li>
          </ul>
          <p class="arch-label">Used by</p>
          <p>Qwen3 4B Instruct, GPT-OSS 20B</p>
        </div>
      </div>
      <div class="arch-shared">Both methods use WebGPU for GPU acceleration. All model weights are cached in your browser after the first download — no server involved.</div>
    </div>
  </div>

  <!-- Loading Screen -->
  <div class="loading-screen" id="loadingScreen">
    <div class="loader-ring"></div>
    <div class="loading-model-name" id="loadingModelName">—</div>
    <div class="loading-label" id="loadingLabel">Initializing engine…</div>
    <div class="progress-bar-container">
      <div class="progress-bar" id="progressBar"></div>
    </div>
    <div class="loading-phases">
      <div class="phase active" id="phaseDownload"><span class="phase-dot"></span> Download</div>
      <div class="phase" id="phaseCompile"><span class="phase-dot"></span> Compile</div>
      <div class="phase" id="phaseReady"><span class="phase-dot"></span> Ready</div>
    </div>
    <div class="loading-stats" id="loadingStats">
      <span id="statProgress">0%</span>
      <span id="statSize">—</span>
      <span id="statElapsed">0s elapsed</span>
    </div>
    <div class="loading-tip" id="loadingTip">Downloading model weights — this only happens once, then it's cached locally.</div>
  </div>

  <!-- Chat Interface -->
  <div class="chat-container" id="chatContainer" style="position:relative;">

    <!-- Settings Panel (collapsible) -->
    <div class="settings-panel" id="settingsPanel">
      <div class="settings-grid">
        <div class="settings-section">
          <h4>System Prompt</h4>
          <select class="preset-select" id="presetSelect" onchange="applyPreset(this.value)">
            <option value="">None (default)</option>
            <option value="custom" disabled hidden>Custom</option>
            <option value="coding">Coding Assistant</option>
            <option value="writing">Writing Editor</option>
            <option value="translator">Translator</option>
            <option value="concise">Concise Answers</option>
          </select>
          <textarea class="system-prompt-input" id="systemPromptInput" placeholder="Enter a system prompt to set the assistant's behavior…" rows="3" oninput="onSystemPromptInput()"></textarea>
        </div>
        <div class="settings-section">
          <h4>Generation</h4>
          <div class="settings-field">
            <label>Temperature <span class="val" id="tempVal">0.7</span></label>
            <input type="range" id="tempSlider" min="0" max="2" step="0.1" value="0.7" oninput="document.getElementById('tempVal').textContent = this.value">
          </div>
          <div class="settings-field">
            <label>Top-P <span class="val" id="topPVal">0.9</span></label>
            <input type="range" id="topPSlider" min="0" max="1" step="0.05" value="0.9" oninput="document.getElementById('topPVal').textContent = this.value">
          </div>
          <div class="settings-field">
            <label>Max Tokens <span class="val" id="maxTokVal">1024</span></label>
            <input type="range" id="maxTokSlider" min="64" max="4096" step="64" value="1024" oninput="document.getElementById('maxTokVal').textContent = this.value">
          </div>
        </div>
        <div class="settings-section kb-section">
          <div class="kb-header">
            <h4>Knowledge Base</h4>
            <label class="kb-toggle" title="Enable RAG retrieval">
              <input type="checkbox" id="kbToggle" onchange="toggleRAG(this.checked)">
              <span class="kb-toggle-slider"></span>
            </label>
          </div>
          <div class="kb-model-status" id="kbModelStatus">
            <span class="status-dot" id="kbStatusDot"></span>
            <span id="kbStatusText">Embedding model not loaded</span>
            <button class="kb-load-btn" id="kbLoadBtn" onclick="loadEmbeddingModel()" style="display:none">Load</button>
          </div>
          <div class="kb-actions">
            <button class="kb-upload-btn" onclick="document.getElementById('kbFileInput').click()">+ Add Document</button>
            <button class="kb-clear-btn" id="kbClearBtn" onclick="clearKnowledgeBase()" style="display:none">Clear All</button>
          </div>
          <input type="file" id="kbFileInput" style="display:none" accept=".txt,.md,.json,.csv,.xml,.yaml,.yml,.html,.css,.js,.ts,.py" onchange="handleKBUpload(this)">
          <div class="kb-docs" id="kbDocs">
            <div class="kb-empty">No documents added</div>
          </div>
        </div>
      </div>
    </div>

    <!-- File Drop Overlay -->
    <div class="file-drop-overlay" id="fileDropOverlay">
      <svg viewBox="0 0 24 24"><path d="M14 2H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h12c1.1 0 2-.9 2-2V8l-6-6zm4 18H6V4h7v5h5v11z"/></svg>
      <span>Drop file to add as context</span>
    </div>

    <div class="messages" id="messages">
      <div class="message system">Model loaded · all processing happens here</div>
    </div>

    <div class="input-area">
      <div class="input-row">
        <button class="file-btn" id="fileBtn" onclick="document.getElementById('fileInput').click()" title="Upload file as context">
          <svg viewBox="0 0 24 24"><path d="M16.5 6v11.5c0 2.21-1.79 4-4 4s-4-1.79-4-4V5a2.5 2.5 0 015 0v10.5c0 .83-.67 1.5-1.5 1.5s-1.5-.67-1.5-1.5V6H9v9.5a3 3 0 006 0V5c0-2.21-1.79-4-4-4S7 2.79 7 5v12.5c0 3.04 2.46 5.5 5.5 5.5s5.5-2.46 5.5-5.5V6h-1.5z"/></svg>
        </button>
        <input type="file" id="fileInput" style="display:none" accept=".txt,.md,.json,.js,.ts,.py,.html,.css,.csv,.xml,.yaml,.yml,.toml,.sh,.rb,.go,.rs,.c,.cpp,.h,.java,.kt,.swift" onchange="handleFileUpload(this)">
        <div class="input-wrapper">
          <textarea
            id="userInput"
            placeholder="Say something…"
            rows="1"
            onkeydown="handleKey(event)"
            oninput="autoResize(this)"
          ></textarea>
        </div>
        <button class="send-btn" id="sendBtn" onclick="sendMessage()" disabled>
          <svg viewBox="0 0 24 24"><path d="M2.01 21L23 12 2.01 3 2 10l15 2-15 2z"/></svg>
        </button>
        <button class="stop-btn" id="stopBtn" onclick="stopGeneration()">
          <svg viewBox="0 0 24 24"><rect x="6" y="6" width="12" height="12" rx="2"/></svg>
        </button>
      </div>
      <div class="input-meta">
        <div class="input-meta-left">
          <span id="modelLabel">—</span>
          <button class="toolbar-btn" id="settingsToggle" onclick="toggleSettings()">
            <svg viewBox="0 0 24 24"><path d="M19.14 12.94c.04-.3.06-.61.06-.94 0-.32-.02-.64-.07-.94l2.03-1.58a.49.49 0 00.12-.61l-1.92-3.32a.49.49 0 00-.59-.22l-2.39.96c-.5-.38-1.03-.7-1.62-.94l-.36-2.54a.48.48 0 00-.48-.41h-3.84a.48.48 0 00-.48.41l-.36 2.54c-.59.24-1.13.57-1.62.94l-2.39-.96a.49.49 0 00-.59.22L2.74 8.87a.48.48 0 00.12.61l2.03 1.58c-.05.3-.07.62-.07.94s.02.64.07.94l-2.03 1.58a.49.49 0 00-.12.61l1.92 3.32c.12.22.37.29.59.22l2.39-.96c.5.38 1.03.7 1.62.94l.36 2.54c.05.24.24.41.48.41h3.84c.24 0 .44-.17.48-.41l.36-2.54c.59-.24 1.13-.56 1.62-.94l2.39.96c.22.08.47 0 .59-.22l1.92-3.32c.12-.22.07-.47-.12-.61l-2.01-1.58zM12 15.6A3.6 3.6 0 1115.6 12 3.6 3.6 0 0112 15.6z"/></svg>
          </button>
          <button class="toolbar-btn" id="newChatBtn" onclick="newChat()">
            <svg viewBox="0 0 24 24"><path d="M19 13h-6v6h-2v-6H5v-2h6V5h2v6h6v2z"/></svg>
            New
          </button>
          <button class="toolbar-btn" onclick="showConversations()">
            <svg viewBox="0 0 24 24"><path d="M20 2H4c-1.1 0-2 .9-2 2v18l4-4h14c1.1 0 2-.9 2-2V4c0-1.1-.9-2-2-2zm0 14H6l-2 2V4h16v12z"/></svg>
            History
          </button>
          <button class="toolbar-btn" onclick="exportConversation()">
            <svg viewBox="0 0 24 24"><path d="M19 9h-4V3H9v6H5l7 7 7-7zM5 18v2h14v-2H5z"/></svg>
            Export
          </button>
        </div>
        <div class="input-meta-right">
          <div class="token-bar" id="tokenBar">
            <div class="token-bar-track"><div class="token-bar-fill" id="tokenBarFill"></div></div>
            <span id="tokenContext">0 tokens</span>
          </div>
          <span id="tokenInfo">Ready</span>
        </div>
      </div>
    </div>
  </div>

  <!-- Conversations Modal -->
  <div class="conv-modal" id="convModal">
    <div class="conv-modal-inner">
      <div class="conv-modal-header">
        <h3>Conversations</h3>
        <button class="conv-modal-close" onclick="hideConversations()">&times;</button>
      </div>
      <div class="conv-list" id="convList">
        <div class="conv-empty">No saved conversations yet</div>
      </div>
    </div>
  </div>
</div>

<script type="module">
  import * as webllm from "https://esm.run/@mlc-ai/web-llm";
  import { pipeline as createPipeline, TextStreamer } from "https://esm.run/@huggingface/transformers@4.0.0-next.3";
  import { marked } from "https://esm.run/marked";

  // ── Available models (curated for reasonable browser download) ──
  const MODELS = [
    {
      id: "SmolLM2-360M-Instruct-q4f16_1-MLC",
      name: "SmolLM2 360M",
      desc: "Tiny & fast. Good for quick experiments.",
      tech: "WebLLM · MLC-compiled WebGPU shaders",
      size: "~250 MB",
      sizeMB: 250,
      time: "~20s – 1 min",
      backend: "webllm",
      tiny: true
    },
    {
      id: "SmolLM2-1.7B-Instruct-q4f16_1-MLC",
      name: "SmolLM2 1.7B",
      desc: "Great balance of size and capability.",
      tech: "WebLLM · MLC-compiled WebGPU shaders",
      size: "~1 GB",
      sizeMB: 1000,
      time: "~1 – 3 min",
      backend: "webllm"
    },
    {
      id: "Llama-3.2-1B-Instruct-q4f16_1-MLC",
      name: "Llama 3.2 1B",
      desc: "Meta's compact model. Strong reasoning.",
      tech: "WebLLM · MLC-compiled WebGPU shaders",
      size: "~700 MB",
      sizeMB: 700,
      time: "~1 – 2 min",
      backend: "webllm"
    },
    {
      id: "Phi-3.5-mini-instruct-q4f16_1-MLC",
      name: "Phi-3.5 Mini",
      desc: "Microsoft's capable small model.",
      tech: "WebLLM · MLC-compiled WebGPU shaders",
      size: "~2.2 GB",
      sizeMB: 2200,
      time: "~3 – 6 min",
      backend: "webllm"
    },
    {
      id: "onnx-community/Qwen3-4B-Instruct-2507-ONNX",
      name: "Qwen3 4B Instruct",
      desc: "Alibaba's Qwen3 instruction-tuned model. Strong multilingual chat.",
      tech: "Transformers.js v4 · ONNX Runtime Web · WebGPU · q4f16",
      size: "~2.9 GB",
      sizeMB: 2900,
      time: "~3 – 7 min",
      backend: "transformers",
      supportsSystemPrompt: true,
      goldilocks: true
    },
    {
      id: "onnx-community/gpt-oss-20b-ONNX",
      name: "GPT-OSS 20B",
      desc: "OpenAI's open-source 20B model. Best quality responses.",
      tech: "Transformers.js v4 · ONNX Runtime Web · WebGPU · q4f16",
      size: "~12.6 GB",
      sizeMB: 12600,
      time: "~10 – 25 min",
      backend: "transformers",
      longLoad: true,
      supportsSystemPrompt: true
    },
  ];

  let selectedModel = null;
  let activeModelId = null;
  let activeBackend = null;
  let engine = null;       // WebLLM engine
  let tfPipeline = null;   // Transformers.js text-generation pipeline
  let embeddingPipeline = null; // Transformers.js embedding pipeline for KB
  let ragEnabled = localStorage.getItem("kb_ragEnabled") === "true";
  let kbDocuments = new Map(); // in-memory metadata cache
  let isGenerating = false;
  let shouldStop = false;

  const EMBEDDING_MODEL = {
    id: "onnx-community/Qwen3-Embedding-0.6B-ONNX",
    task: "feature-extraction",
  };
  let chatHistory = [];
  let hasWebGPU = false;
  let currentConvId = null;

  // Configure marked
  marked.setOptions({ breaks: true, gfm: true });

  // ── System Prompt Presets ──
  const PRESETS = {
    coding: "You are an expert programming assistant. Write clean, well-structured code. Explain your approach briefly. Use markdown code blocks with language tags.",
    writing: "You are a skilled writing editor. Help improve clarity, grammar, and style. Be constructive and specific with suggestions. Preserve the author's voice.",
    translator: "You are a professional translator. Translate text accurately while preserving tone and nuance. If the source language isn't specified, detect it. Always state the detected source language.",
    concise: "Be concise. Answer in as few words as possible while remaining accurate and helpful. Use bullet points for lists. Skip pleasantries.",
  };

  window.applyPreset = function (key) {
    if (key === "custom") return; // "Custom" is display-only
    const input = document.getElementById("systemPromptInput");
    input.value = PRESETS[key] || "";
    onSystemPromptInput();
  };

  window.onSystemPromptInput = function () {
    const input = document.getElementById("systemPromptInput");
    const select = document.getElementById("presetSelect");
    const customText = input.value.trim();

    if (!customText) {
      select.value = "";
      return;
    }

    // Check if the text matches a preset
    const matchedKey = Object.entries(PRESETS).find(([, v]) => v === customText)?.[0];
    select.value = matchedKey || "custom";
  };

  function updateSystemPromptAvailability() {
    const model = MODELS.find(m => m.id === activeModelId);
    const supported = model?.supportsSystemPrompt === true;
    const input = document.getElementById("systemPromptInput");
    const select = document.getElementById("presetSelect");
    const section = input.closest(".settings-section");

    input.disabled = !supported;
    select.disabled = !supported;

    if (!supported) {
      input.placeholder = "System prompts are not supported by this model";
      input.value = "";
      select.value = "";
      section.style.opacity = "0.4";
      section.title = "This model does not reliably follow system prompts";
    } else {
      input.placeholder = "Enter a system prompt to set the assistant's behavior…";
      section.style.opacity = "";
      section.title = "";
      onSystemPromptInput();
    }
  }

  // ── Settings Panel ──
  window.toggleSettings = function () {
    const panel = document.getElementById("settingsPanel");
    const btn = document.getElementById("settingsToggle");
    panel.classList.toggle("active");
    btn.classList.toggle("active");
  };

  function getGenParams() {
    return {
      temperature: parseFloat(document.getElementById("tempSlider").value),
      top_p: parseFloat(document.getElementById("topPSlider").value),
      max_tokens: parseInt(document.getElementById("maxTokSlider").value),
    };
  }

  function getSystemPrompt() {
    const input = document.getElementById("systemPromptInput");
    return input ? input.value.trim() : "";
  }

  // ── IndexedDB Persistence ──
  const DB_NAME = "thinkhere";
  const DB_NAME_OLD = "localmind";
  const DB_VERSION = 2;
  const STORE_NAME = "conversations";
  const KB_STORE_NAME = "kb_chunks";
  const KB_META_STORE_NAME = "kb_metadata";

  function openDB() {
    return new Promise((resolve, reject) => {
      const req = indexedDB.open(DB_NAME, DB_VERSION);
      req.onupgradeneeded = (e) => {
        const db = e.target.result;
        if (!db.objectStoreNames.contains(STORE_NAME)) {
          db.createObjectStore(STORE_NAME, { keyPath: "id" });
        }
        if (!db.objectStoreNames.contains(KB_STORE_NAME)) {
          const chunkStore = db.createObjectStore(KB_STORE_NAME, { keyPath: "id", autoIncrement: true });
          chunkStore.createIndex("docId", "docId", { unique: false });
        }
        if (!db.objectStoreNames.contains(KB_META_STORE_NAME)) {
          db.createObjectStore(KB_META_STORE_NAME, { keyPath: "docId" });
        }
      };
      req.onsuccess = () => resolve(req.result);
      req.onerror = () => reject(req.error);
    });
  }

  // Migrate data from old "localmind" DB to new "thinkhere" DB
  async function migrateFromOldDB() {
    try {
      if (localStorage.getItem("db_migrated")) return;
      const oldReq = indexedDB.open(DB_NAME_OLD);
      const oldDB = await new Promise((resolve, reject) => {
        oldReq.onsuccess = () => resolve(oldReq.result);
        oldReq.onerror = () => reject(oldReq.error);
      });

      const storeNames = Array.from(oldDB.objectStoreNames);
      if (storeNames.length === 0) { oldDB.close(); localStorage.setItem("db_migrated", "1"); return; }

      const newDB = await openDB();

      for (const storeName of storeNames) {
        if (!newDB.objectStoreNames.contains(storeName)) continue;
        const oldTx = oldDB.transaction(storeName, "readonly");
        const items = await new Promise((resolve) => {
          const req = oldTx.objectStore(storeName).getAll();
          req.onsuccess = () => resolve(req.result || []);
          req.onerror = () => resolve([]);
        });
        if (items.length > 0) {
          const newTx = newDB.transaction(storeName, "readwrite");
          const store = newTx.objectStore(storeName);
          for (const item of items) store.put(item);
        }
      }

      oldDB.close();
      indexedDB.deleteDatabase(DB_NAME_OLD);
      localStorage.setItem("db_migrated", "1");
      console.log("Migrated data from localmind to thinkhere DB");
    } catch (e) {
      console.error("DB migration failed (non-fatal):", e);
      localStorage.setItem("db_migrated", "1");
    }
  }

  async function saveConversation() {
    if (chatHistory.length === 0) return;
    const id = currentConvId || Date.now().toString();
    currentConvId = id;
    const firstUserMsg = chatHistory.find(m => m.role === "user");
    const title = firstUserMsg ? firstUserMsg.content.slice(0, 60) : "New conversation";
    const conv = {
      id,
      title,
      model: activeModelId,
      modelName: MODELS.find(m => m.id === activeModelId)?.name || "Unknown",
      messages: chatHistory,
      systemPrompt: getSystemPrompt(),
      updatedAt: new Date().toISOString(),
    };
    try {
      const db = await openDB();
      const tx = db.transaction(STORE_NAME, "readwrite");
      tx.objectStore(STORE_NAME).put(conv);
    } catch (e) { console.error("Failed to save conversation:", e); }
  }

  async function loadConversationList() {
    try {
      const db = await openDB();
      const tx = db.transaction(STORE_NAME, "readonly");
      const req = tx.objectStore(STORE_NAME).getAll();
      return new Promise((resolve) => {
        req.onsuccess = () => resolve(req.result.sort((a, b) => b.updatedAt.localeCompare(a.updatedAt)));
        req.onerror = () => resolve([]);
      });
    } catch { return []; }
  }

  async function deleteConversation(id) {
    try {
      const db = await openDB();
      const tx = db.transaction(STORE_NAME, "readwrite");
      tx.objectStore(STORE_NAME).delete(id);
    } catch (e) { console.error(e); }
  }

  async function loadConversation(id) {
    try {
      const db = await openDB();
      const tx = db.transaction(STORE_NAME, "readonly");
      const req = tx.objectStore(STORE_NAME).get(id);
      return new Promise((resolve) => {
        req.onsuccess = () => resolve(req.result);
        req.onerror = () => resolve(null);
      });
    } catch { return null; }
  }

  // ── Knowledge Base: Embedding Model ──
  function showKBLoadingOverlay(title, subtitle) {
    const overlay = document.getElementById("kbLoadingOverlay");
    document.getElementById("kbLoadingTitle").textContent = title;
    document.getElementById("kbLoadingSubtitle").textContent = subtitle;
    document.getElementById("kbLoadingBarFill").style.width = "0%";
    document.getElementById("kbLoadingText").textContent = "0%";
    overlay.classList.add("active");
  }

  function hideKBLoadingOverlay() {
    document.getElementById("kbLoadingOverlay").classList.remove("active");
  }

  function updateKBLoadingProgress(pct, text) {
    document.getElementById("kbLoadingBarFill").style.width = `${pct}%`;
    document.getElementById("kbLoadingText").textContent = text || `${pct}%`;
  }

  function updateKBModelStatus(state) {
    const dot = document.getElementById("kbStatusDot");
    const text = document.getElementById("kbStatusText");
    const btn = document.getElementById("kbLoadBtn");
    dot.className = "status-dot";
    if (state === "loaded") {
      dot.classList.add("loaded");
      text.textContent = "Embedding model ready";
      btn.style.display = "none";
    } else if (state === "loading") {
      dot.classList.add("loading");
      text.textContent = "Loading…";
      btn.style.display = "none";
    } else {
      text.textContent = "Embedding model not loaded";
      btn.style.display = kbDocuments.size > 0 ? "inline-block" : "none";
    }
  }

  window.loadEmbeddingModel = async function () {
    if (embeddingPipeline) return;
    updateKBModelStatus("loading");
    showKBLoadingOverlay("Loading Embedding Model", "Downloading model weights — this only happens once, then it's cached locally.");
    try {
      const totalSize = 600 * 1e6; // ~600MB approximate
      const fileProgress = new Map();
      embeddingPipeline = await createPipeline(EMBEDDING_MODEL.task, EMBEDDING_MODEL.id, {
        dtype: "q4",
        device: "webgpu",
        progress_callback: (p) => {
          if (p.status === "progress" && typeof p.loaded === "number") {
            fileProgress.set(p.file, p.loaded);
            const loaded = Array.from(fileProgress.values()).reduce((a, b) => a + b, 0);
            const pct = Math.min(99, Math.round((loaded / totalSize) * 100));
            updateKBLoadingProgress(pct, `${pct}% — ${(loaded / 1e6).toFixed(0)} / ${(totalSize / 1e6).toFixed(0)} MB`);
          } else if (p.status === "ready") {
            updateKBLoadingProgress(100, "Initializing…");
          }
        },
      });
      updateKBModelStatus("loaded");
      hideKBLoadingOverlay();
    } catch (err) {
      console.error("Failed to load embedding model:", err);
      updateKBModelStatus("unloaded");
      hideKBLoadingOverlay();
      alert("Failed to load embedding model: " + err.message);
    }
  };

  async function embedText(text) {
    if (!embeddingPipeline) throw new Error("Embedding model not loaded");
    const output = await embeddingPipeline(text, { pooling: "mean", normalize: true });
    return new Float32Array(output.data);
  }

  // ── Knowledge Base: Document Chunking ──
  function chunkDocument(text) {
    const TARGET_CHARS = 2048; // ~512 tokens
    const OVERLAP_CHARS = 600; // ~150 tokens
    const paragraphs = text.split(/\n\s*\n/).filter(p => p.trim());
    const chunks = [];
    let buffer = "";

    for (const para of paragraphs) {
      const trimmed = para.trim();
      if (!trimmed) continue;

      if (buffer.length + trimmed.length + 2 > TARGET_CHARS && buffer.length > 0) {
        chunks.push(buffer.trim());
        const overlap = getOverlapText(buffer, OVERLAP_CHARS);
        buffer = overlap + "\n\n" + trimmed;
      } else {
        buffer += (buffer ? "\n\n" : "") + trimmed;
      }
    }

    if (buffer.trim()) {
      chunks.push(buffer.trim());
    }

    // Split any oversized chunks
    const finalChunks = [];
    for (const chunk of chunks) {
      if (chunk.length > TARGET_CHARS * 1.5) {
        finalChunks.push(...splitLargeSegment(chunk, TARGET_CHARS));
      } else {
        finalChunks.push(chunk);
      }
    }

    return finalChunks.length > 0 ? finalChunks : [text.trim()];
  }

  function splitLargeSegment(text, targetChars) {
    const sentences = text.match(/[^.!?\n]+[.!?\n]+|[^.!?\n]+$/g) || [text];
    const parts = [];
    let current = "";
    for (const sentence of sentences) {
      if (current.length + sentence.length > targetChars && current.length > 0) {
        parts.push(current.trim());
        current = sentence;
      } else {
        current += sentence;
      }
    }
    if (current.trim()) parts.push(current.trim());
    return parts;
  }

  function getOverlapText(text, overlapChars) {
    if (text.length <= overlapChars) return text;
    return text.slice(-overlapChars);
  }

  // ── Knowledge Base: Keyword Extraction ──
  const STOPWORDS = new Set([
    "a","an","the","and","or","but","in","on","at","to","for","of","with","by",
    "from","is","it","this","that","are","was","were","be","been","being","have",
    "has","had","do","does","did","will","would","could","should","may","might",
    "shall","can","not","no","nor","so","if","then","than","too","very","just",
    "about","above","after","again","all","also","am","any","because","before",
    "between","both","each","few","get","got","he","her","here","him","his","how",
    "i","its","let","me","more","most","my","new","now","of","off","old","once",
    "only","other","our","out","over","own","same","she","some","such","them",
    "there","these","they","those","through","under","up","us","we","what","when",
    "where","which","while","who","whom","why","you","your",
  ]);

  function extractKeywords(text, topK = 20) {
    const words = text.toLowerCase().replace(/[^a-z0-9\s]/g, " ").split(/\s+/).filter(w => w.length > 2 && !STOPWORDS.has(w));
    const freq = {};
    for (const w of words) freq[w] = (freq[w] || 0) + 1;
    const sorted = Object.entries(freq).sort((a, b) => b[1] - a[1]);
    const keywords = sorted.slice(0, topK).map(([word]) => word);
    return { keywords, freq };
  }

  // ── Knowledge Base: Document Upload & Storage ──
  window.handleKBUpload = async function (input) {
    const file = input.files[0];
    if (!file) return;
    input.value = "";

    const text = await file.text();
    if (!text.trim()) { alert("File is empty."); return; }

    if (!embeddingPipeline) {
      await loadEmbeddingModel();
      if (!embeddingPipeline) return; // loading failed
    }

    await processAndStoreDocument(file.name, text, file.size);
  };

  async function processAndStoreDocument(fileName, text, fileSize) {
    const docId = Date.now().toString() + "_" + Math.random().toString(36).slice(2, 8);
    const chunks = chunkDocument(text);

    showKBLoadingOverlay("Processing Document", `Embedding ${chunks.length} chunks from "${fileName}"…`);

    const db = await openDB();
    const BATCH_SIZE = 5;

    for (let i = 0; i < chunks.length; i += BATCH_SIZE) {
      const batch = chunks.slice(i, i + BATCH_SIZE);
      const embeddings = await Promise.all(batch.map(c => embedText(c)));

      const tx = db.transaction(KB_STORE_NAME, "readwrite");
      const store = tx.objectStore(KB_STORE_NAME);

      for (let j = 0; j < batch.length; j++) {
        const { keywords, freq } = extractKeywords(batch[j]);
        store.put({
          docId,
          chunkIndex: i + j,
          text: batch[j],
          embedding: Array.from(embeddings[j]),
          keywords,
          wordFreq: freq,
        });
      }

      const pct = Math.round(((i + batch.length) / chunks.length) * 100);
      updateKBLoadingProgress(pct, `${i + batch.length} / ${chunks.length} chunks`);
    }

    // Store metadata
    const meta = {
      docId,
      fileName,
      fileSize,
      chunkCount: chunks.length,
      addedAt: new Date().toISOString(),
    };

    const metaTx = db.transaction(KB_META_STORE_NAME, "readwrite");
    metaTx.objectStore(KB_META_STORE_NAME).put(meta);

    kbDocuments.set(docId, meta);
    hideKBLoadingOverlay();
    refreshKBDocList();

    // Auto-enable RAG
    if (!ragEnabled) {
      ragEnabled = true;
      localStorage.setItem("kb_ragEnabled", "true");
      document.getElementById("kbToggle").checked = true;
    }
  }

  // ── Knowledge Base: Document List Management ──
  async function refreshKBDocList() {
    try {
      const db = await openDB();
      const tx = db.transaction(KB_META_STORE_NAME, "readonly");
      const req = tx.objectStore(KB_META_STORE_NAME).getAll();
      const docs = await new Promise((resolve) => {
        req.onsuccess = () => resolve(req.result || []);
        req.onerror = () => resolve([]);
      });

      kbDocuments.clear();
      docs.forEach(d => kbDocuments.set(d.docId, d));

      const container = document.getElementById("kbDocs");
      const clearBtn = document.getElementById("kbClearBtn");

      if (docs.length === 0) {
        container.innerHTML = '<div class="kb-empty">No documents added</div>';
        clearBtn.style.display = "none";
      } else {
        container.innerHTML = docs.map(d => {
          const size = d.fileSize >= 1024 * 1024
            ? (d.fileSize / (1024 * 1024)).toFixed(1) + " MB"
            : (d.fileSize / 1024).toFixed(1) + " KB";
          return `<div class="kb-doc-item">
            <span class="doc-name" title="${d.fileName}">${d.fileName}</span>
            <span class="doc-meta">${d.chunkCount} chunks · ${size}</span>
            <button class="doc-remove" onclick="removeKBDocument('${d.docId}')" title="Remove">×</button>
          </div>`;
        }).join("");
        clearBtn.style.display = "inline-block";
      }

      updateKBModelStatus(embeddingPipeline ? "loaded" : "unloaded");
    } catch (e) {
      console.error("Failed to refresh KB doc list:", e);
    }
  }

  window.removeKBDocument = async function (docId) {
    try {
      const db = await openDB();

      // Delete all chunks for this doc
      const tx = db.transaction(KB_STORE_NAME, "readwrite");
      const store = tx.objectStore(KB_STORE_NAME);
      const index = store.index("docId");
      const req = index.openCursor(IDBKeyRange.only(docId));
      await new Promise((resolve, reject) => {
        req.onsuccess = (e) => {
          const cursor = e.target.result;
          if (cursor) {
            cursor.delete();
            cursor.continue();
          } else {
            resolve();
          }
        };
        req.onerror = () => reject(req.error);
      });

      // Delete metadata
      const metaTx = db.transaction(KB_META_STORE_NAME, "readwrite");
      metaTx.objectStore(KB_META_STORE_NAME).delete(docId);

      kbDocuments.delete(docId);
      refreshKBDocList();
    } catch (e) {
      console.error("Failed to remove KB document:", e);
    }
  };

  window.clearKnowledgeBase = async function () {
    if (!confirm("Remove all documents from the knowledge base?")) return;
    try {
      const db = await openDB();
      const tx1 = db.transaction(KB_STORE_NAME, "readwrite");
      tx1.objectStore(KB_STORE_NAME).clear();
      const tx2 = db.transaction(KB_META_STORE_NAME, "readwrite");
      tx2.objectStore(KB_META_STORE_NAME).clear();
      kbDocuments.clear();
      ragEnabled = false;
      localStorage.setItem("kb_ragEnabled", "false");
      document.getElementById("kbToggle").checked = false;
      refreshKBDocList();
    } catch (e) {
      console.error("Failed to clear KB:", e);
    }
  };

  // ── Knowledge Base: Hybrid Retrieval ──
  function cosineSimilarity(vecA, vecB) {
    let dot = 0, normA = 0, normB = 0;
    for (let i = 0; i < vecA.length; i++) {
      dot += vecA[i] * vecB[i];
      normA += vecA[i] * vecA[i];
      normB += vecB[i] * vecB[i];
    }
    const denom = Math.sqrt(normA) * Math.sqrt(normB);
    return denom === 0 ? 0 : dot / denom;
  }

  function calculateKeywordScore(queryKeywords, chunkKeywords, chunkWordFreq) {
    const qSet = new Set(queryKeywords);
    const cSet = new Set(chunkKeywords);
    const intersection = [...qSet].filter(w => cSet.has(w));
    const union = new Set([...qSet, ...cSet]);
    if (union.size === 0) return 0;

    // Jaccard similarity
    const jaccard = intersection.length / union.size;

    // BM25-like frequency boost
    let freqBoost = 0;
    for (const word of intersection) {
      const tf = chunkWordFreq[word] || 1;
      freqBoost += Math.log(1 + tf);
    }
    const maxBoost = Math.max(1, intersection.length * Math.log(1 + 5));

    return 0.6 * jaccard + 0.4 * (freqBoost / maxBoost);
  }

  async function retrieveRelevantChunks(query, topK = 5) {
    if (!embeddingPipeline || kbDocuments.size === 0) return [];

    const queryVec = await embedText(query);
    const { keywords: queryKeywords } = extractKeywords(query);

    const db = await openDB();
    const tx = db.transaction(KB_STORE_NAME, "readonly");
    const allChunks = await new Promise((resolve) => {
      const req = tx.objectStore(KB_STORE_NAME).getAll();
      req.onsuccess = () => resolve(req.result || []);
      req.onerror = () => resolve([]);
    });

    const scored = allChunks.map(chunk => {
      const chunkVec = new Float32Array(chunk.embedding);
      const semanticScore = cosineSimilarity(queryVec, chunkVec);
      const keywordScore = calculateKeywordScore(queryKeywords, chunk.keywords || [], chunk.wordFreq || {});
      const score = 0.7 * semanticScore + 0.3 * keywordScore;
      return { ...chunk, score, semanticScore, keywordScore };
    });

    scored.sort((a, b) => b.score - a.score);
    return scored.slice(0, topK);
  }

  // ── Knowledge Base: Toggle ──
  window.toggleRAG = async function (enabled) {
    ragEnabled = enabled;
    localStorage.setItem("kb_ragEnabled", String(ragEnabled));
    if (enabled && !embeddingPipeline && kbDocuments.size > 0) {
      await loadEmbeddingModel();
      if (!embeddingPipeline) {
        ragEnabled = false;
        localStorage.setItem("kb_ragEnabled", "false");
        document.getElementById("kbToggle").checked = false;
      }
    }
  };

  window.showConversations = async function () {
    const list = document.getElementById("convList");
    const convs = await loadConversationList();
    if (convs.length === 0) {
      list.innerHTML = '<div class="conv-empty">No saved conversations yet</div>';
    } else {
      list.innerHTML = convs.map(c => {
        const date = new Date(c.updatedAt);
        const dateStr = date.toLocaleDateString(undefined, { month: "short", day: "numeric" });
        const msgCount = c.messages.filter(m => m.role === "user").length;
        return `<div class="conv-item" onclick="restoreConversation('${c.id}')">
          <div class="conv-item-info">
            <div class="conv-item-title">${c.title}</div>
            <div class="conv-item-meta">${c.modelName || "?"} · ${msgCount} msgs · ${dateStr}</div>
          </div>
          <button class="conv-item-delete" onclick="event.stopPropagation(); deleteAndRefresh('${c.id}')">Delete</button>
        </div>`;
      }).join("");
    }
    document.getElementById("convModal").classList.add("active");
  };

  window.hideConversations = function () {
    document.getElementById("convModal").classList.remove("active");
  };

  window.deleteAndRefresh = async function (id) {
    await deleteConversation(id);
    if (currentConvId === id) { currentConvId = null; }
    showConversations();
  };

  window.restoreConversation = async function (id) {
    const conv = await loadConversation(id);
    if (!conv) return;
    hideConversations();
    chatHistory = conv.messages;
    currentConvId = conv.id;
    if (conv.systemPrompt) {
      document.getElementById("systemPromptInput").value = conv.systemPrompt;
      onSystemPromptInput();
    }
    // Re-render messages
    const container = document.getElementById("messages");
    container.innerHTML = '<div class="message system">Conversation restored · all processing happens here</div>';
    for (const msg of chatHistory) {
      const div = appendMessage(msg.role, msg.content);
      if (msg.role === "assistant") {
        div.innerHTML = marked.parse(msg.content);
        div.classList.add("rendered");
      }
    }
    updateTokenCount();
  };

  window.newChat = function () {
    chatHistory = [];
    currentConvId = null;
    const container = document.getElementById("messages");
    container.innerHTML = '<div class="message system">New conversation · all processing happens here</div>';
    document.getElementById("systemPromptInput").value = "";
    document.getElementById("presetSelect").value = "";
    updateTokenCount();
  };

  // ── Export ──
  window.exportConversation = function () {
    if (chatHistory.length === 0) return;
    const sysPrompt = getSystemPrompt();
    let md = "# ThinkHere Conversation\n\n";
    if (sysPrompt) md += `**System:** ${sysPrompt}\n\n---\n\n`;
    for (const msg of chatHistory) {
      const label = msg.role === "user" ? "**You**" : "**Assistant**";
      md += `${label}\n\n${msg.content}\n\n---\n\n`;
    }
    const blob = new Blob([md], { type: "text/markdown" });
    const url = URL.createObjectURL(blob);
    const a = document.createElement("a");
    a.href = url;
    a.download = `thinkhere-${new Date().toISOString().slice(0, 10)}.md`;
    a.click();
    URL.revokeObjectURL(url);
  };

  // ── File Upload / Drop ──
  window.handleFileUpload = function (input) {
    const file = input.files[0];
    if (!file) return;
    readAndInjectFile(file);
    input.value = "";
  };

  function readAndInjectFile(file) {
    const reader = new FileReader();
    reader.onload = (e) => {
      const content = e.target.result;
      const truncated = content.length > 50000 ? content.slice(0, 50000) + "\n\n[Truncated — file too large]" : content;
      const contextMsg = `<file name="${file.name}" size="${file.size}" type="${file.type}">\n${truncated}\n</file>`;
      chatHistory.push({ role: "user", content: contextMsg });

      // Show file indicator in chat
      const container = document.getElementById("messages");
      const div = document.createElement("div");
      div.className = "message file-context";
      div.textContent = `📎 ${file.name} (${(file.size / 1024).toFixed(1)} KB) added as context`;
      container.appendChild(div);
      scrollToBottom();
      updateTokenCount();
    };
    reader.readAsText(file);
  }

  // File drag-and-drop on chat container
  function setupFileDrop() {
    const chat = document.getElementById("chatContainer");
    const overlay = document.getElementById("fileDropOverlay");
    let dragCounter = 0;

    chat.addEventListener("dragenter", (e) => {
      e.preventDefault();
      dragCounter++;
      overlay.classList.add("active");
    });

    chat.addEventListener("dragleave", (e) => {
      e.preventDefault();
      dragCounter--;
      if (dragCounter <= 0) { overlay.classList.remove("active"); dragCounter = 0; }
    });

    chat.addEventListener("dragover", (e) => e.preventDefault());

    chat.addEventListener("drop", (e) => {
      e.preventDefault();
      dragCounter = 0;
      overlay.classList.remove("active");
      const file = e.dataTransfer.files[0];
      if (file) readAndInjectFile(file);
    });
  }

  // ── Token Count ──
  function estimateTokens(text) {
    // Rough approximation: ~4 chars per token for English
    return Math.ceil(text.length / 4);
  }

  function updateTokenCount() {
    const sysPrompt = getSystemPrompt();
    let total = sysPrompt ? estimateTokens(sysPrompt) : 0;
    for (const msg of chatHistory) {
      total += estimateTokens(msg.content) + 4; // +4 for role/formatting overhead
    }
    const maxCtx = 4096; // conservative default
    const pct = Math.min((total / maxCtx) * 100, 100);

    document.getElementById("tokenContext").textContent = `~${total} tokens`;
    const fill = document.getElementById("tokenBarFill");
    fill.style.width = `${pct}%`;
    fill.classList.remove("warn", "danger");
    if (pct > 85) fill.classList.add("danger");
    else if (pct > 65) fill.classList.add("warn");
  }

  // ── Stop Generation ──
  window.stopGeneration = function () {
    shouldStop = true;
    if (activeBackend === "webllm" && engine) {
      try { engine.interruptGenerate(); } catch (e) { console.error(e); }
    }
  };

  function showStopButton() {
    document.getElementById("sendBtn").style.display = "none";
    const stop = document.getElementById("stopBtn");
    stop.classList.add("active");
  }

  function hideStopButton() {
    document.getElementById("stopBtn").classList.remove("active");
    document.getElementById("sendBtn").style.display = "";
  };

  // ── Check WebGPU Support ──
  async function checkWebGPU() {
    const container = document.getElementById("webgpuCheck");
    if (!navigator.gpu) {
      container.innerHTML = `<div class="webgpu-warning">
        <strong>WebGPU not available.</strong><br>
        WebLLM models require WebGPU (Chrome 113+, Edge 113+). Transformers.js models can still run via ONNX Runtime Web.
      </div>`;
      return false;
    }
    try {
      const adapter = await navigator.gpu.requestAdapter();
      if (!adapter) throw new Error("No adapter");
      return true;
    } catch {
      container.innerHTML = `<div class="webgpu-warning">
        WebGPU adapter not found. WebLLM models may not work, but Transformers.js models can still run.
      </div>`;
      return false;
    }
  }

  // ── Check which models are cached in browser storage ──
  async function getCachedModelIds() {
    try {
      const cacheNames = await caches.keys();
      const cachedIds = new Set();

      // Quick pass: cache name contains model ID (WebLLM pattern)
      for (const m of MODELS) {
        if (cacheNames.some(name => name.includes(m.id))) {
          cachedIds.add(m.id);
        }
      }

      // Deep pass: check inside cache entries for Transformers.js models
      const unchecked = MODELS.filter(m => !cachedIds.has(m.id));
      if (unchecked.length > 0) {
        for (const cacheName of cacheNames) {
          try {
            const cache = await caches.open(cacheName);
            const keys = await cache.keys();
            const urls = keys.map(r => r.url);
            for (const m of unchecked) {
              if (!cachedIds.has(m.id) && urls.some(u => u.includes(m.id.replace(/\//g, "%2F")) || u.includes(m.id))) {
                cachedIds.add(m.id);
              }
            }
          } catch { /* skip inaccessible caches */ }
        }
      }

      return cachedIds;
    } catch {
      return new Set();
    }
  }

  // ── Build Model Grid ──
  async function buildModelGrid() {
    const grid = document.getElementById("modelGrid");
    grid.innerHTML = "";
    selectedModel = null;

    const cachedIds = await getCachedModelIds();

    MODELS.forEach((m) => {
      const isActive = m.id === activeModelId;
      const isCached = cachedIds.has(m.id);
      const isDisabled = m.backend === "webllm" && !hasWebGPU;

      const card = document.createElement("div");
      card.className = "model-card";
      if (isActive) card.classList.add("active-model");
      else if (isCached) card.classList.add("cached");
      if (isDisabled) {
        card.style.opacity = "0.4";
        card.style.cursor = "not-allowed";
      }

      const cachedHTML = isCached ? `<span class="cached-label">cached</span>` : "";

      const tinyHTML = m.tiny ? `<span class="tiny-label">good for testing</span>` : "";
      const longLoadHTML = m.longLoad ? `<span class="long-load-label">long download</span>` : "";
      const goldilocksHTML = m.goldilocks ? `<span class="goldilocks-label">goldilocks</span>` : "";

      card.innerHTML = `
        <h3>${m.name}${tinyHTML}${longLoadHTML}${goldilocksHTML}</h3>
        <div class="model-desc">${m.desc}</div>
        <div class="model-tech">${m.tech}</div>
        <div class="model-size">${m.size}</div>
        <div class="model-time">${isCached ? "✓ Cached locally" : "⏱ First download: " + m.time}</div>
        ${cachedHTML}
      `;

      // Cached label click: clear model from cache
      const cachedLbl = card.querySelector(".cached-label");
      if (cachedLbl) {
        cachedLbl.addEventListener("click", async (e) => {
          e.stopPropagation();
          if (!confirm(`Remove ${m.name} from cache? You'll need to re-download it next time.`)) return;
          try {
            const cacheNames = await caches.keys();
            for (const name of cacheNames) {
              if (name.includes(m.id)) {
                await caches.delete(name);
                continue;
              }
              const cache = await caches.open(name);
              const keys = await cache.keys();
              for (const req of keys) {
                if (req.url.includes(m.id) || req.url.includes(m.id.replace(/\//g, "%2F"))) {
                  await cache.delete(req);
                }
              }
            }
            // If this was the active model, unload it
            if (m.id === activeModelId) await unloadModel();
            await buildModelGrid();
          } catch (err) {
            console.error("Failed to clear cache:", err);
          }
        });
      }

      card.addEventListener("click", () => {
        if (isDisabled) return;
        document.querySelectorAll(".model-card").forEach(c => c.classList.remove("selected"));
        card.classList.add("selected");
        selectedModel = m;
        const btn = document.getElementById("loadBtn");
        btn.disabled = false;
        if (isActive) {
          btn.textContent = `Continue with ${m.name}`;
        } else if (activeModelId) {
          btn.textContent = `Switch to ${m.name}`;
        } else if (isCached) {
          btn.textContent = `Load ${m.name}`;
        } else {
          btn.textContent = `Download & Load ${m.name}`;
        }
      });

      grid.appendChild(card);
    });

    // Reset load button
    const btn = document.getElementById("loadBtn");
    if (activeModelId) {
      btn.disabled = true;
      btn.textContent = "Select a different model";
    } else {
      btn.disabled = true;
      btn.textContent = "Select a model";
    }
  }

  // ── Reset Loading Screen ──
  function resetLoadingScreen() {
    const loadScreen = document.getElementById("loadingScreen");
    loadScreen.classList.remove("active");
    loadScreen.style.display = "";
    document.getElementById("progressBar").style.width = "0%";
    document.getElementById("progressBar").style.background = "";
    document.getElementById("loadingLabel").textContent = "Initializing engine…";
    document.getElementById("loadingModelName").textContent = "—";
    document.getElementById("statProgress").textContent = "0%";
    document.getElementById("statSize").textContent = "—";
    document.getElementById("statElapsed").textContent = "0s elapsed";
    document.getElementById("loadingTip").textContent = "Downloading model weights — this only happens once, then it's cached locally.";

    // Remove any appended error blocks
    const loadScreen2 = document.getElementById("loadingScreen");
    loadScreen2.querySelectorAll(".network-error").forEach(el => el.remove());

    // Reset phase indicators
    const phaseDownload = document.getElementById("phaseDownload");
    const phaseCompile = document.getElementById("phaseCompile");
    const phaseReady = document.getElementById("phaseReady");
    [phaseDownload, phaseCompile, phaseReady].forEach(p => p.classList.remove("active", "done"));
    phaseDownload.classList.add("active");
  }

  // ── Show Model Selector ──
  window.showModelSelector = async function () {
    // Hide chat
    document.getElementById("chatContainer").classList.remove("active");
    // Show model selector
    const selector = document.getElementById("modelSelector");
    selector.style.display = "";
    // Refresh grid with current cache/active states
    await buildModelGrid();
  };

  // ── Unload Model ──
  async function unloadModel() {
    if (engine) {
      try { await engine.unload(); } catch (e) { console.error(e); }
      engine = null;
    }
    tfPipeline = null;
    activeModelId = null;
    activeBackend = null;
    selectedModel = null;
    chatHistory = [];

    // Hide change model button, reset header
    document.getElementById("changeModelBtn").style.display = "none";
    document.getElementById("headerStatus").textContent = "";

    // Refresh the grid
    await buildModelGrid();
  }
  window.unloadModel = unloadModel;

  // ── Load Model ──
  window.loadModel = async function () {
    if (!selectedModel) return;

    // If continuing with the already-active model, just return to chat
    if (selectedModel.id === activeModelId && (engine || tfPipeline)) {
      document.getElementById("modelSelector").style.display = "none";
      document.getElementById("chatContainer").classList.add("active");
      document.getElementById("userInput").focus();
      updateSystemPromptAvailability();
      return;
    }

    // If switching models, unload the current engine first
    if (engine && activeModelId) {
      try { await engine.unload(); } catch (e) { console.error(e); }
      engine = null;
    }
    tfPipeline = null;
    activeModelId = null;
    activeBackend = null;

    // Clear chat for fresh conversation
    chatHistory = [];
    document.getElementById("messages").innerHTML =
      '<div class="message system">Model loaded · all processing happens here</div>';

    // Hide selector, reset and show loading screen
    document.getElementById("modelSelector").style.display = "none";
    document.getElementById("chatContainer").classList.remove("active");
    resetLoadingScreen();
    const loadScreen = document.getElementById("loadingScreen");
    loadScreen.classList.add("active");

    const label = document.getElementById("loadingLabel");
    const bar = document.getElementById("progressBar");
    const statProgress = document.getElementById("statProgress");
    const statSize = document.getElementById("statSize");
    const statElapsed = document.getElementById("statElapsed");
    const tip = document.getElementById("loadingTip");

    // Set model name
    document.getElementById("loadingModelName").textContent = selectedModel.name;

    // Phase management
    const phases = {
      download: document.getElementById("phaseDownload"),
      compile: document.getElementById("phaseCompile"),
      ready: document.getElementById("phaseReady"),
    };

    function setPhase(name) {
      Object.entries(phases).forEach(([key, el]) => {
        el.classList.remove("active", "done");
        if (key === name) el.classList.add("active");
      });
      const order = ["download", "compile", "ready"];
      const idx = order.indexOf(name);
      for (let i = 0; i < idx; i++) {
        phases[order[i]].classList.remove("active");
        phases[order[i]].classList.add("done");
      }
    }

    // Tips that rotate
    const tips = selectedModel.backend === "transformers" ? [
      "Downloading ONNX model weights — this only happens once, then it's cached locally.",
      "All data stays on your device. Nothing is sent to any server.",
      "ONNX Runtime Web runs inference efficiently in your browser.",
      "After caching, this model will load in just a few seconds next time.",
      "Larger models produce better responses but need more memory.",
    ] : [
      "Downloading model weights — this only happens once, then it's cached locally.",
      "All data stays on your device. Nothing is sent to any server.",
      "Larger models produce better responses but take longer to download.",
      "After caching, this model will load in just a few seconds next time.",
      "WebGPU accelerates inference using your device's GPU.",
    ];
    let tipIdx = 0;
    const tipInterval = setInterval(() => {
      tipIdx = (tipIdx + 1) % tips.length;
      tip.style.opacity = 0;
      setTimeout(() => {
        tip.textContent = tips[tipIdx];
        tip.style.opacity = 1;
      }, 300);
    }, 5000);

    // Elapsed timer
    const startTime = performance.now();
    const timerInterval = setInterval(() => {
      const secs = Math.floor((performance.now() - startTime) / 1000);
      const min = Math.floor(secs / 60);
      const sec = secs % 60;
      statElapsed.textContent = min > 0 ? `${min}m ${sec}s elapsed` : `${sec}s elapsed`;
    }, 1000);

    let currentPhase = "download";
    setPhase("download");

    try {
      if (selectedModel.backend === "transformers") {
        // ── Transformers.js v4 / ONNX Runtime Web path ──
        const TOTAL_FILE_SIZE = selectedModel.sizeMB * 1e6; // approximate total bytes
        const fileProgress = new Map();
        label.textContent = "Loading ONNX model via Transformers.js…";
        tfPipeline = await createPipeline("text-generation", selectedModel.id, {
          dtype: "q4f16",
          device: "webgpu",
          progress_callback: (p) => {
            if (p.status === "progress" && typeof p.loaded === "number") {
              fileProgress.set(p.file, p.loaded);
              const loaded = Array.from(fileProgress.values()).reduce((a, b) => a + b, 0);
              const pct = Math.round((loaded / TOTAL_FILE_SIZE) * 100);
              bar.style.width = `${pct}%`;
              statProgress.textContent = `${pct}%`;
              label.textContent = `Downloading model… ${pct}%`;
              if (TOTAL_FILE_SIZE >= 1e9) {
                statSize.textContent = `${(loaded / 1e9).toFixed(1)} / ${(TOTAL_FILE_SIZE / 1e9).toFixed(1)} GB`;
              } else {
                statSize.textContent = `${(loaded / 1e6).toFixed(0)} / ${(TOTAL_FILE_SIZE / 1e6).toFixed(0)} MB`;
              }
            } else if (p.status === "initiate") {
              label.textContent = p.file ? `Loading ${p.file}…` : "Initializing…";
            } else if (p.status === "ready") {
              if (currentPhase !== "compile") {
                currentPhase = "compile";
                setPhase("compile");
                label.textContent = "Compiling WebGPU shaders…";
                tip.textContent = "Setting up the ONNX inference session for your GPU.";
              }
            }
          },
        });
      } else {
        // ── WebLLM / WebGPU path ──
        engine = await webllm.CreateMLCEngine(selectedModel.id, {
          initProgressCallback: (report) => {
            const text = report.text || "";
            label.textContent = text;

            // Detect phase from WebLLM's progress messages
            if (text.toLowerCase().includes("compil") || text.toLowerCase().includes("shader")) {
              if (currentPhase !== "compile") {
                currentPhase = "compile";
                setPhase("compile");
                tip.textContent = "Compiling GPU shaders for your hardware — also cached after first run.";
              }
            }

            // Update progress bar and percentage
            if (report.progress !== undefined) {
              const pct = Math.round(report.progress * 100);
              bar.style.width = `${pct}%`;
              statProgress.textContent = `${pct}%`;
            }

            // Estimate downloaded size
            if (report.progress !== undefined && selectedModel.sizeMB) {
              const downloaded = Math.round(report.progress * selectedModel.sizeMB);
              if (downloaded >= 1000) {
                statSize.textContent = `${(downloaded / 1000).toFixed(1)} / ${(selectedModel.sizeMB / 1000).toFixed(1)} GB`;
              } else {
                statSize.textContent = `${downloaded} / ${selectedModel.sizeMB} MB`;
              }
            }
          },
        });
      }

      // Done
      clearInterval(timerInterval);
      clearInterval(tipInterval);
      setPhase("ready");
      label.textContent = "Ready!";
      bar.style.width = "100%";
      statProgress.textContent = "100%";
      activeModelId = selectedModel.id;
      activeBackend = selectedModel.backend;

      await new Promise(r => setTimeout(r, 600));

      // Transition to chat
      loadScreen.classList.remove("active");
      loadScreen.style.display = "none";
      document.getElementById("chatContainer").classList.add("active");
      document.getElementById("modelLabel").textContent = selectedModel.name;
      document.getElementById("headerStatus").textContent = selectedModel.name;
      document.getElementById("changeModelBtn").style.display = "inline-block";
      document.getElementById("sendBtn").disabled = false;
      document.getElementById("userInput").focus();
      currentConvId = null;
      updateTokenCount();
      updateSystemPromptAvailability();

    } catch (err) {
      clearInterval(timerInterval);
      clearInterval(tipInterval);
      bar.style.background = "#e05050";
      console.error(err);

      const msg = (err.message || "").toLowerCase();
      const isNetworkError = msg.includes("failed to fetch")
        || msg.includes("cors")
        || msg.includes("403")
        || msg.includes("network")
        || msg.includes("blocked");

      if (isNetworkError) {
        label.textContent = "Network error — unable to download model";
        tip.textContent = "";
        tip.innerHTML = "";
        const errorDiv = document.createElement("div");
        errorDiv.className = "network-error";
        errorDiv.innerHTML = `
          <strong>Blocked by network policy</strong>
          Model weights are hosted on Hugging Face and could not be reached. This typically happens on corporate or restricted networks that block external domains.
          <br><br>
          Ask your IT team to allow access to these domains:
          <ul>
            <li><code>huggingface.co</code> — model weights</li>
            <li><code>esm.run</code> — JavaScript module CDN</li>
          </ul>
          <a href="#" onclick="showModelSelector(); return false;" style="color: var(--accent); text-decoration: underline;">Back to models</a>
        `;
        document.getElementById("loadingScreen").appendChild(errorDiv);
      } else {
        label.textContent = `Error: ${err.message}`;
        tip.textContent = "";
        tip.innerHTML = 'Something went wrong. Try refreshing or selecting a smaller model. <a href="#" onclick="showModelSelector(); return false;" style="color: var(--accent); text-decoration: underline;">Back to models</a>';
      }
    }
  };

  // ── Send Message ──
  window.sendMessage = async function () {
    const input = document.getElementById("userInput");
    const text = input.value.trim();
    if (!text || isGenerating || (!engine && !tfPipeline)) return;

    // Add user message
    appendMessage("user", text);
    chatHistory.push({ role: "user", content: text });
    input.value = "";
    autoResize(input);
    isGenerating = true;
    shouldStop = false;
    showStopButton();
    document.getElementById("tokenInfo").textContent = "Generating…";

    // Build messages array
    const sysPrompt = getSystemPrompt();
    const messages = [];
    if (sysPrompt) messages.push({ role: "system", content: sysPrompt });
    messages.push(...chatHistory);

    // RAG: retrieve relevant chunks and prepend to the last user message
    // Injected into the user turn (not system prompt) so small models reliably attend to it
    const RAG_MAX_CHARS = 3000;
    const RAG_MIN_SCORE = 0.15;
    if (ragEnabled && kbDocuments.size > 0) {
      try {
        if (!embeddingPipeline) await loadEmbeddingModel();
        if (!embeddingPipeline) throw new Error("Embedding model unavailable");
        const relevantChunks = await retrieveRelevantChunks(text);
        const usable = relevantChunks.filter(c => c.score >= RAG_MIN_SCORE);
        if (usable.length > 0) {
          const contextParts = [];
          let totalChars = 0;
          for (let i = 0; i < usable.length; i++) {
            let chunkText = usable[i].text;
            const header = `[Source ${i + 1}]:\n`;
            if (totalChars + header.length + chunkText.length > RAG_MAX_CHARS) {
              const remaining = RAG_MAX_CHARS - totalChars - header.length;
              if (remaining > 200) {
                chunkText = chunkText.slice(0, remaining) + "…";
              } else {
                break;
              }
            }
            contextParts.push(header + chunkText);
            totalChars += header.length + chunkText.length;
          }

          // Rewrite the last user message in the messages array (chatHistory stays clean)
          const lastIdx = messages.length - 1;
          const originalQuestion = messages[lastIdx].content;
          messages[lastIdx] = {
            role: "user",
            content: `Use the following context to answer the question.\n\n${contextParts.join("\n\n")}\n\nQuestion: ${originalQuestion}`,
          };

          const indicator = document.createElement("div");
          indicator.className = "kb-rag-indicator";
          indicator.textContent = `Retrieved ${contextParts.length} relevant chunk${contextParts.length === 1 ? "" : "s"} from knowledge base`;
          document.getElementById("messages").appendChild(indicator);
          scrollToBottom();
        }
      } catch (e) {
        console.error("RAG retrieval failed:", e);
      }
    }

    const params = getGenParams();

    // Create assistant message bubble for streaming
    const bubble = appendMessage("assistant", "");
    let fullResponse = "";
    const startTime = performance.now();
    let tokenCount = 0;

    try {
      if (activeBackend === "transformers" && tfPipeline) {
        // ── Transformers.js streaming generation ──
        const streamer = new TextStreamer(tfPipeline.tokenizer, {
          skip_prompt: true,
          callback_function: (token) => {
            if (shouldStop) return;
            fullResponse += token;
            tokenCount++;
            bubble.textContent = fullResponse;
            scrollToBottom();
          },
        });

        await tfPipeline(messages, {
          max_new_tokens: params.max_tokens,
          temperature: params.temperature,
          top_p: params.top_p,
          do_sample: params.temperature > 0,
          streamer,
          stopping_criteria: [() => shouldStop],
        });

        chatHistory.push({ role: "assistant", content: fullResponse });

        const elapsed = (performance.now() - startTime) / 1000;
        const tps = (tokenCount / elapsed).toFixed(1);
        document.getElementById("tokenInfo").textContent = `${tokenCount} tokens · ${tps} tok/s`;

      } else {
        // ── WebLLM streaming generation ──
        const reply = await engine.chat.completions.create({
          messages,
          temperature: params.temperature,
          top_p: params.top_p,
          max_tokens: params.max_tokens,
          stream: true,
        });

        for await (const chunk of reply) {
          if (shouldStop) break;
          const delta = chunk.choices[0]?.delta?.content || "";
          fullResponse += delta;
          tokenCount++;
          bubble.textContent = fullResponse;
          scrollToBottom();
        }

        chatHistory.push({ role: "assistant", content: fullResponse });

        const elapsed = (performance.now() - startTime) / 1000;
        const tps = (tokenCount / elapsed).toFixed(1);
        document.getElementById("tokenInfo").textContent = `${tokenCount} tokens · ${tps} tok/s`;
      }

      // Render markdown after streaming completes
      if (fullResponse) {
        bubble.innerHTML = marked.parse(fullResponse);
        bubble.classList.add("rendered");
      }

    } catch (err) {
      if (!shouldStop) {
        bubble.textContent = `[Error: ${err.message}]`;
        console.error(err);
        document.getElementById("tokenInfo").textContent = "Error";
      }
    }

    isGenerating = false;
    shouldStop = false;
    hideStopButton();
    document.getElementById("sendBtn").disabled = false;
    document.getElementById("userInput").focus();
    updateTokenCount();
    saveConversation();
  };

  // ── Helpers ──
  function appendMessage(role, text) {
    const container = document.getElementById("messages");
    const div = document.createElement("div");
    div.className = `message ${role}`;
    div.textContent = text;
    container.appendChild(div);
    scrollToBottom();
    return div;
  }

  function scrollToBottom() {
    const m = document.getElementById("messages");
    m.scrollTop = m.scrollHeight;
  }

  window.handleKey = function (e) {
    if (e.key === "Enter" && !e.shiftKey) {
      e.preventDefault();
      sendMessage();
    }
  };

  window.autoResize = function (el) {
    el.style.height = "auto";
    el.style.height = Math.min(el.scrollHeight, 150) + "px";
  };

  // ── Global scroll forwarding ──
  // App uses overflow:hidden on the root container, so wheel events outside
  // the scrollable panel are swallowed. Forward them to whichever panel is active.
  document.addEventListener('wheel', (e) => {
    const selector = document.getElementById('modelSelector');
    if (selector && selector.offsetHeight > 0 && !selector.contains(e.target)) {
      selector.scrollTop += e.deltaY;
      return;
    }
    const messages = document.getElementById('messages');
    if (messages && messages.offsetHeight > 0 && !messages.contains(e.target)) {
      messages.scrollTop += e.deltaY;
    }
  }, { passive: true });

  // ── GitHub stats ──
  fetch("https://api.github.com/repos/ipattis/thinkhere")
    .then(r => r.json())
    .then(data => {
      const fmt = n => n >= 1000 ? (n / 1000).toFixed(1) + "k" : String(n);
      if (data.stargazers_count != null) document.getElementById("ghStars").textContent = fmt(data.stargazers_count);
      if (data.forks_count != null) document.getElementById("ghForks").textContent = fmt(data.forks_count);
    })
    .catch(() => {});

  // ── Init ──
  (async () => {
    hasWebGPU = await checkWebGPU();
    await buildModelGrid();
    setupFileDrop();
    // Pre-initialize IndexedDB and migrate from old DB name
    try { await openDB(); await migrateFromOldDB(); } catch (e) { console.error("IndexedDB init failed:", e); }
    // Restore knowledge base state
    try {
      await refreshKBDocList();
      document.getElementById("kbToggle").checked = ragEnabled;
    } catch (e) { console.error("KB init failed:", e); }
  })();
</script>

<div class="kb-loading-overlay" id="kbLoadingOverlay">
  <div class="kb-loading-title" id="kbLoadingTitle">Loading Embedding Model</div>
  <div class="kb-loading-subtitle" id="kbLoadingSubtitle">Downloading model weights — this only happens once.</div>
  <div class="kb-loading-bar"><div class="kb-loading-bar-fill" id="kbLoadingBarFill"></div></div>
  <div class="kb-loading-text" id="kbLoadingText">0%</div>
</div>

</body>
</html>
